{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ace27b",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511eac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\harsu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef20404",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Dataset\n",
    "data= gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "## Save dataset to a file\n",
    "with open('hamlet.txt', 'w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d82baa",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2063f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c3e454d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2712"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Dataset\n",
    "with open('hamlet.txt','r')as file:\n",
    "    text= file.read(70000).lower() # Limiting data read to 70,000 characters due to memory read issue\n",
    "\n",
    "\n",
    "## Tokenize the text\n",
    "tokenizer= Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words= len(tokenizer.word_index)+1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1dba3a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 611],\n",
       " [1, 611, 4],\n",
       " [1, 611, 4, 52],\n",
       " [1, 611, 4, 52, 38],\n",
       " [1, 611, 4, 52, 38, 980],\n",
       " [1, 611, 4, 52, 38, 980, 981],\n",
       " [1, 611, 4, 52, 38, 980, 981, 982],\n",
       " [612, 983],\n",
       " [612, 983, 984],\n",
       " [612, 983, 984, 985],\n",
       " [70, 219],\n",
       " [70, 219, 2],\n",
       " [70, 219, 2, 613],\n",
       " [70, 219, 2, 613, 220],\n",
       " [70, 219, 2, 613, 220, 986],\n",
       " [219, 614],\n",
       " [219, 614, 48],\n",
       " [221, 162],\n",
       " [221, 162, 356],\n",
       " [221, 162, 356, 20],\n",
       " [221, 162, 356, 20, 276],\n",
       " [221, 162, 356, 20, 276, 436],\n",
       " [21, 60],\n",
       " [250, 222],\n",
       " [250, 222, 309],\n",
       " [250, 222, 309, 1],\n",
       " [250, 222, 309, 1, 39],\n",
       " [221, 219],\n",
       " [250, 25],\n",
       " [221, 7],\n",
       " [221, 7, 62],\n",
       " [221, 7, 62, 40],\n",
       " [221, 7, 62, 40, 987],\n",
       " [221, 7, 62, 40, 987, 90],\n",
       " [221, 7, 62, 40, 987, 90, 21],\n",
       " [221, 7, 62, 40, 987, 90, 21, 437],\n",
       " [250, 79],\n",
       " [250, 79, 69],\n",
       " [250, 79, 69, 988],\n",
       " [250, 79, 69, 988, 438],\n",
       " [250, 79, 69, 988, 438, 615],\n",
       " [250, 79, 69, 988, 438, 615, 71],\n",
       " [250, 79, 69, 988, 438, 615, 71, 3],\n",
       " [250, 79, 69, 988, 438, 615, 71, 3, 439],\n",
       " [250, 79, 69, 988, 438, 615, 71, 3, 439, 613],\n",
       " [221, 22],\n",
       " [221, 22, 18],\n",
       " [221, 22, 18, 989],\n",
       " [221, 22, 18, 989, 104],\n",
       " [221, 22, 18, 989, 104, 277],\n",
       " [221, 22, 18, 989, 104, 277, 79],\n",
       " [221, 22, 18, 989, 104, 277, 79, 616],\n",
       " [221, 22, 18, 989, 104, 277, 79, 616, 617],\n",
       " [2, 6],\n",
       " [2, 6, 83],\n",
       " [2, 6, 83, 990],\n",
       " [2, 6, 83, 990, 47],\n",
       " [2, 6, 83, 990, 47, 139],\n",
       " [176, 27],\n",
       " [176, 27, 7],\n",
       " [176, 27, 7, 99],\n",
       " [176, 27, 7, 99, 440],\n",
       " [176, 27, 7, 99, 440, 991],\n",
       " [221, 12],\n",
       " [221, 12, 8],\n",
       " [221, 12, 8, 992],\n",
       " [221, 12, 8, 992, 993],\n",
       " [176, 54],\n",
       " [176, 54, 618],\n",
       " [176, 54, 618, 45],\n",
       " [176, 54, 618, 45, 7],\n",
       " [176, 54, 618, 45, 7, 72],\n",
       " [176, 54, 618, 45, 7, 72, 441],\n",
       " [176, 54, 618, 45, 7, 72, 441, 110],\n",
       " [176, 54, 618, 45, 7, 72, 441, 110, 2],\n",
       " [177, 1],\n",
       " [177, 1, 994],\n",
       " [177, 1, 994, 4],\n",
       " [177, 1, 994, 4, 5],\n",
       " [177, 1, 994, 4, 5, 163],\n",
       " [177, 1, 994, 4, 5, 163, 442],\n",
       " [177, 1, 994, 4, 5, 163, 442, 96],\n",
       " [177, 1, 994, 4, 5, 163, 442, 96, 108],\n",
       " [177, 1, 994, 4, 5, 163, 442, 96, 108, 140],\n",
       " [70, 110],\n",
       " [70, 110, 2],\n",
       " [70, 110, 2, 177],\n",
       " [221, 6],\n",
       " [221, 6, 91],\n",
       " [221, 6, 91, 6],\n",
       " [221, 6, 91, 6, 122],\n",
       " [221, 6, 91, 6, 122, 96],\n",
       " [221, 6, 91, 6, 122, 96, 276],\n",
       " [221, 6, 91, 6, 122, 96, 276, 614],\n",
       " [221, 6, 91, 6, 122, 96, 276, 614, 48],\n",
       " [32, 151],\n",
       " [32, 151, 3],\n",
       " [32, 151, 3, 18],\n",
       " [32, 151, 3, 18, 443],\n",
       " [63, 2],\n",
       " [63, 2, 995],\n",
       " [63, 2, 995, 357],\n",
       " [63, 2, 995, 357, 3],\n",
       " [63, 2, 995, 357, 3, 1],\n",
       " [63, 2, 995, 357, 3, 1, 444],\n",
       " [221, 97],\n",
       " [221, 97, 7],\n",
       " [221, 97, 7, 41],\n",
       " [221, 97, 7, 41, 73],\n",
       " [63, 164],\n",
       " [63, 164, 996],\n",
       " [63, 164, 996, 223],\n",
       " [63, 164, 996, 223, 997],\n",
       " [63, 164, 996, 223, 997, 117],\n",
       " [63, 164, 996, 223, 997, 117, 76],\n",
       " [63, 164, 996, 223, 997, 117, 76, 998],\n",
       " [63, 164, 996, 223, 997, 117, 76, 998, 7],\n",
       " [999, 219],\n",
       " [999, 219, 224],\n",
       " [999, 219, 224, 5],\n",
       " [999, 219, 224, 5, 619],\n",
       " [999, 219, 224, 5, 619, 97],\n",
       " [999, 219, 224, 5, 619, 97, 7],\n",
       " [999, 219, 224, 5, 619, 97, 7, 618],\n",
       " [199, 221],\n",
       " [63, 1000],\n",
       " [63, 1000, 219],\n",
       " [250, 84],\n",
       " [250, 84, 26],\n",
       " [250, 84, 26, 15],\n",
       " [250, 84, 26, 15, 110],\n",
       " [250, 84, 26, 15, 110, 48],\n",
       " [32, 8],\n",
       " [32, 8, 445],\n",
       " [32, 8, 445, 4],\n",
       " [32, 8, 445, 4, 29],\n",
       " [250, 128],\n",
       " [250, 128, 110],\n",
       " [250, 128, 110, 128],\n",
       " [250, 128, 110, 128, 41],\n",
       " [250, 128, 110, 128, 41, 177],\n",
       " [63, 26],\n",
       " [63, 26, 224],\n",
       " [63, 26, 224, 18],\n",
       " [63, 26, 224, 18, 152],\n",
       " [63, 26, 224, 18, 152, 446],\n",
       " [63, 26, 224, 18, 152, 446, 123],\n",
       " [63, 26, 224, 18, 152, 446, 123, 3],\n",
       " [63, 26, 224, 18, 152, 446, 123, 3, 73],\n",
       " [250, 6],\n",
       " [250, 6, 27],\n",
       " [250, 6, 27, 165],\n",
       " [250, 6, 27, 165, 225],\n",
       " [63, 110],\n",
       " [63, 110, 620],\n",
       " [63, 110, 620, 79],\n",
       " [63, 110, 620, 79, 19],\n",
       " [63, 110, 620, 79, 19, 30],\n",
       " [63, 110, 620, 79, 19, 30, 621],\n",
       " [2, 42],\n",
       " [2, 42, 12],\n",
       " [2, 42, 12, 64],\n",
       " [2, 42, 12, 64, 1001],\n",
       " [2, 42, 12, 64, 1001, 109],\n",
       " [2, 42, 12, 64, 1001, 109, 141],\n",
       " [2, 42, 12, 64, 1001, 109, 141, 4],\n",
       " [2, 42, 12, 64, 1001, 109, 141, 4, 29],\n",
       " [447, 18],\n",
       " [447, 18, 1002],\n",
       " [447, 18, 1002, 358],\n",
       " [447, 18, 1002, 358, 448],\n",
       " [447, 18, 1002, 358, 448, 165],\n",
       " [447, 18, 1002, 358, 448, 165, 4],\n",
       " [447, 18, 1002, 358, 448, 165, 4, 92],\n",
       " [310, 6],\n",
       " [310, 6, 27],\n",
       " [310, 6, 27, 1003],\n",
       " [310, 6, 27, 1003, 29],\n",
       " [310, 6, 27, 1003, 29, 622],\n",
       " [16, 92],\n",
       " [16, 92, 3],\n",
       " [16, 92, 3, 163],\n",
       " [16, 92, 3, 163, 1],\n",
       " [16, 92, 3, 163, 1, 1004],\n",
       " [16, 92, 3, 163, 1, 1004, 4],\n",
       " [16, 92, 3, 163, 1, 1004, 4, 18],\n",
       " [16, 92, 3, 163, 1, 1004, 4, 18, 73],\n",
       " [11, 45],\n",
       " [11, 45, 123],\n",
       " [11, 45, 123, 18],\n",
       " [11, 45, 123, 18, 623],\n",
       " [11, 45, 123, 18, 623, 62],\n",
       " [25, 77],\n",
       " [25, 77, 1005],\n",
       " [25, 77, 1005, 30],\n",
       " [25, 77, 1005, 30, 142],\n",
       " [25, 77, 1005, 30, 142, 2],\n",
       " [25, 77, 1005, 30, 142, 2, 57],\n",
       " [25, 77, 1005, 30, 142, 2, 57, 3],\n",
       " [25, 77, 1005, 30, 142, 2, 57, 3, 9],\n",
       " [32, 624],\n",
       " [32, 624, 624],\n",
       " [32, 624, 624, 625],\n",
       " [32, 624, 624, 625, 12],\n",
       " [32, 624, 624, 625, 12, 449],\n",
       " [250, 359],\n",
       " [250, 359, 129],\n",
       " [250, 359, 129, 8],\n",
       " [250, 359, 129, 8, 226],\n",
       " [2, 64],\n",
       " [2, 64, 92],\n",
       " [2, 64, 92, 178],\n",
       " [2, 64, 92, 178, 123],\n",
       " [2, 64, 92, 178, 123, 1006],\n",
       " [2, 64, 92, 178, 123, 1006, 21],\n",
       " [2, 64, 92, 178, 123, 1006, 21, 360],\n",
       " [11, 35],\n",
       " [11, 35, 24],\n",
       " [11, 35, 24, 1007],\n",
       " [11, 35, 24, 1007, 179],\n",
       " [11, 35, 24, 1007, 179, 30],\n",
       " [11, 35, 24, 1007, 179, 30, 1008],\n",
       " [26, 33],\n",
       " [26, 33, 220],\n",
       " [26, 33, 220, 450],\n",
       " [26, 33, 220, 450, 27],\n",
       " [26, 33, 220, 450, 27, 165],\n",
       " [32, 54],\n",
       " [32, 54, 359],\n",
       " [32, 54, 359, 33],\n",
       " [32, 54, 359, 33, 129],\n",
       " [2, 64],\n",
       " [2, 64, 92],\n",
       " [2, 64, 92, 122],\n",
       " [2, 64, 92, 122, 219],\n",
       " [2, 64, 92, 122, 219, 57],\n",
       " [2, 64, 92, 122, 219, 57, 4],\n",
       " [2, 64, 92, 122, 219, 57, 4, 18],\n",
       " [176, 278],\n",
       " [176, 278, 73],\n",
       " [176, 278, 73, 4],\n",
       " [176, 278, 73, 4, 36],\n",
       " [111, 1009],\n",
       " [111, 1009, 279],\n",
       " [111, 1009, 279, 626],\n",
       " [111, 1009, 279, 626, 280],\n",
       " [111, 1009, 279, 626, 280, 1010],\n",
       " [111, 1009, 279, 626, 280, 1010, 58],\n",
       " [111, 1009, 279, 626, 280, 1010, 58, 1],\n",
       " [111, 1009, 279, 626, 280, 1010, 58, 1, 1011],\n",
       " [99, 153],\n",
       " [99, 153, 14],\n",
       " [99, 153, 14, 451],\n",
       " [99, 153, 14, 451, 452],\n",
       " [99, 153, 14, 451, 452, 1012],\n",
       " [99, 153, 14, 451, 452, 1012, 11],\n",
       " [99, 153, 14, 451, 452, 1012, 11, 200],\n",
       " [99, 153, 14, 451, 452, 1012, 11, 200, 4],\n",
       " [99, 153, 14, 451, 452, 1012, 11, 200, 4, 80],\n",
       " [112, 69],\n",
       " [112, 69, 9],\n",
       " [112, 69, 9, 627],\n",
       " [112, 69, 9, 627, 177],\n",
       " [112, 69, 9, 627, 177, 2],\n",
       " [112, 69, 9, 627, 177, 2, 5],\n",
       " [112, 69, 9, 627, 177, 2, 5, 60],\n",
       " [1, 1013],\n",
       " [1, 1013, 31],\n",
       " [1, 1013, 31, 1014],\n",
       " [1, 1013, 31, 1014, 118],\n",
       " [63, 453],\n",
       " [63, 453, 311],\n",
       " [63, 453, 311, 71],\n",
       " [63, 453, 311, 71, 4],\n",
       " [70, 1],\n",
       " [70, 1, 113],\n",
       " [130, 112],\n",
       " [130, 112, 9],\n",
       " [130, 112, 9, 154],\n",
       " [130, 112, 9, 154, 123],\n",
       " [176, 10],\n",
       " [176, 10, 1],\n",
       " [176, 10, 1, 279],\n",
       " [176, 10, 1, 279, 454],\n",
       " [176, 10, 1, 279, 454, 49],\n",
       " [176, 10, 1, 279, 454, 49, 1],\n",
       " [176, 10, 1, 279, 454, 49, 1, 39],\n",
       " [176, 10, 1, 279, 454, 49, 1, 39, 280],\n",
       " [176, 10, 1, 279, 454, 49, 1, 39, 280, 251],\n",
       " [63, 55],\n",
       " [63, 55, 180],\n",
       " [63, 55, 180, 8],\n",
       " [63, 55, 180, 8, 1015],\n",
       " [63, 55, 180, 8, 1015, 57],\n",
       " [63, 55, 180, 8, 1015, 57, 3],\n",
       " [63, 55, 180, 8, 1015, 57, 3, 9],\n",
       " [63, 55, 180, 8, 1015, 57, 3, 9, 110],\n",
       " [176, 455],\n",
       " [176, 455, 9],\n",
       " [176, 455, 9, 12],\n",
       " [176, 455, 9, 12, 49],\n",
       " [176, 455, 9, 12, 49, 1],\n",
       " [176, 455, 9, 12, 49, 1, 39],\n",
       " [176, 455, 9, 12, 49, 1, 39, 281],\n",
       " [176, 455, 9, 12, 49, 1, 39, 281, 9],\n",
       " [176, 455, 9, 12, 49, 1, 39, 281, 9, 110],\n",
       " [1016, 40],\n",
       " [1016, 40, 49],\n",
       " [1016, 40, 49, 9],\n",
       " [1016, 40, 49, 9, 1017],\n",
       " [1016, 40, 49, 9, 1017, 20],\n",
       " [1016, 40, 49, 9, 1017, 20, 16],\n",
       " [1016, 40, 49, 9, 1017, 20, 16, 1018],\n",
       " [1016, 40, 49, 9, 1017, 20, 16, 1018, 1019],\n",
       " [176, 9],\n",
       " [176, 9, 81],\n",
       " [176, 9, 81, 28],\n",
       " [176, 9, 81, 28, 1020],\n",
       " [176, 9, 81, 28, 1020, 105],\n",
       " [63, 282],\n",
       " [63, 282, 9],\n",
       " [63, 282, 9, 110],\n",
       " [32, 26],\n",
       " [32, 26, 180],\n",
       " [32, 26, 180, 55],\n",
       " [32, 26, 180, 55, 11],\n",
       " [32, 26, 180, 55, 11, 1021],\n",
       " [32, 26, 180, 55, 11, 1021, 18],\n",
       " [32, 26, 180, 55, 11, 1021, 18, 93],\n",
       " [32, 26, 180, 55, 11, 1021, 18, 93, 4],\n",
       " [32, 26, 180, 55, 11, 1021, 18, 93, 4, 73],\n",
       " [201, 16],\n",
       " [201, 16, 11],\n",
       " [201, 16, 11, 312],\n",
       " [201, 16, 11, 312, 2],\n",
       " [201, 16, 11, 312, 2, 628],\n",
       " [201, 16, 11, 312, 2, 628, 361],\n",
       " [10, 74],\n",
       " [10, 74, 1],\n",
       " [10, 74, 1, 629],\n",
       " [10, 74, 1, 629, 4],\n",
       " [10, 74, 1, 629, 4, 1022],\n",
       " [10, 74, 1, 629, 4, 1022, 119],\n",
       " [65, 362],\n",
       " [65, 362, 630],\n",
       " [65, 362, 630, 38],\n",
       " [65, 362, 630, 38, 80],\n",
       " [65, 362, 630, 38, 80, 6],\n",
       " [65, 362, 630, 38, 80, 6, 313],\n",
       " [65, 362, 630, 38, 80, 6, 313, 71],\n",
       " [65, 362, 630, 38, 80, 6, 313, 71, 57],\n",
       " [63, 9],\n",
       " [63, 9, 15],\n",
       " [63, 9, 15, 1023],\n",
       " [176, 114],\n",
       " [176, 114, 9],\n",
       " [176, 114, 9, 1024],\n",
       " [176, 114, 9, 1024, 166],\n",
       " [32, 283],\n",
       " [32, 283, 57],\n",
       " [32, 283, 57, 57],\n",
       " [32, 283, 57, 57, 6],\n",
       " [32, 283, 57, 57, 6, 313],\n",
       " [32, 283, 57, 57, 6, 313, 71],\n",
       " [32, 283, 57, 57, 6, 313, 71, 57],\n",
       " [199, 1],\n",
       " [199, 1, 113],\n",
       " [63, 79],\n",
       " [63, 79, 284],\n",
       " [63, 79, 284, 2],\n",
       " [63, 79, 284, 2, 42],\n",
       " [63, 79, 284, 2, 42, 12],\n",
       " [63, 79, 284, 2, 42, 12, 356],\n",
       " [176, 86],\n",
       " [176, 86, 69],\n",
       " [176, 86, 69, 110],\n",
       " [176, 86, 69, 110, 7],\n",
       " [176, 86, 69, 110, 7, 1025],\n",
       " [176, 86, 69, 110, 7, 1025, 456],\n",
       " [176, 86, 69, 110, 7, 1025, 456, 314],\n",
       " [15, 12],\n",
       " [15, 12, 18],\n",
       " [15, 12, 18, 315],\n",
       " [15, 12, 18, 315, 50],\n",
       " [15, 12, 18, 315, 50, 31],\n",
       " [15, 12, 18, 315, 50, 31, 621],\n",
       " [26, 91],\n",
       " [26, 91, 7],\n",
       " [26, 91, 7, 457],\n",
       " [32, 155],\n",
       " [32, 155, 5],\n",
       " [32, 155, 5, 124],\n",
       " [32, 155, 5, 124, 6],\n",
       " [32, 155, 5, 124, 6, 131],\n",
       " [32, 155, 5, 124, 6, 131, 12],\n",
       " [32, 155, 5, 124, 6, 131, 12, 18],\n",
       " [32, 155, 5, 124, 6, 131, 12, 18, 227],\n",
       " [363, 1],\n",
       " [363, 1, 1026],\n",
       " [363, 1, 1026, 2],\n",
       " [363, 1, 1026, 2, 132],\n",
       " [363, 1, 1026, 2, 132, 1027],\n",
       " [4, 106],\n",
       " [4, 106, 228],\n",
       " [4, 106, 228, 142],\n",
       " [63, 15],\n",
       " [63, 15, 9],\n",
       " [63, 15, 9, 12],\n",
       " [63, 15, 9, 12, 49],\n",
       " [63, 15, 9, 12, 49, 1],\n",
       " [63, 15, 9, 12, 49, 1, 39],\n",
       " [32, 23],\n",
       " [32, 23, 55],\n",
       " [32, 23, 55, 180],\n",
       " [32, 23, 55, 180, 3],\n",
       " [32, 23, 55, 180, 3, 46],\n",
       " [32, 23, 55, 180, 3, 46, 60],\n",
       " [94, 56],\n",
       " [94, 56, 1],\n",
       " [94, 56, 1, 85],\n",
       " [94, 56, 1, 85, 1028],\n",
       " [94, 56, 1, 85, 1028, 25],\n",
       " [94, 56, 1, 85, 1028, 25, 99],\n",
       " [94, 56, 1, 85, 1028, 25, 99, 43],\n",
       " [111, 143],\n",
       " [111, 143, 631],\n",
       " [111, 143, 631, 316],\n",
       " [111, 143, 631, 316, 1029],\n",
       " [24, 1030],\n",
       " [24, 1030, 25],\n",
       " [24, 1030, 25, 178],\n",
       " [24, 1030, 25, 178, 111],\n",
       " [24, 1030, 25, 178, 111, 10],\n",
       " [24, 1030, 25, 178, 111, 10, 87],\n",
       " [24, 1030, 25, 178, 111, 10, 87, 1031],\n",
       " [24, 1030, 25, 178, 111, 10, 87, 1031, 1032],\n",
       " [25, 1033],\n",
       " [25, 1033, 1],\n",
       " [25, 1033, 1, 1034],\n",
       " [25, 1033, 1, 1034, 1035],\n",
       " [25, 1033, 1, 1034, 1035, 43],\n",
       " [25, 1033, 1, 1034, 1035, 43, 1],\n",
       " [25, 1033, 1, 1034, 1035, 43, 1, 1036],\n",
       " [79, 252],\n",
       " [63, 100],\n",
       " [63, 100, 448],\n",
       " [63, 100, 448, 155],\n",
       " [63, 100, 448, 155, 2],\n",
       " [63, 100, 448, 155, 2, 1037],\n",
       " [63, 100, 448, 155, 2, 1037, 47],\n",
       " [63, 100, 448, 155, 2, 1037, 47, 18],\n",
       " [63, 100, 448, 155, 2, 1037, 47, 18, 251],\n",
       " [63, 100, 448, 155, 2, 1037, 47, 18, 251, 437],\n",
       " [16, 1038],\n",
       " [16, 1038, 1039],\n",
       " [16, 1038, 1039, 76],\n",
       " [16, 1038, 1039, 76, 25],\n",
       " [16, 1038, 1039, 76, 25, 284],\n",
       " [16, 1038, 1039, 76, 25, 284, 38],\n",
       " [16, 1038, 1039, 76, 25, 284, 38, 30],\n",
       " [16, 1038, 1039, 76, 25, 284, 38, 30, 163],\n",
       " [32, 10],\n",
       " [32, 10, 26],\n",
       " [32, 10, 26, 317],\n",
       " [32, 10, 26, 317, 632],\n",
       " [32, 10, 26, 317, 632, 3],\n",
       " [32, 10, 26, 317, 632, 3, 1040],\n",
       " [32, 10, 26, 317, 632, 3, 1040, 6],\n",
       " [32, 10, 26, 317, 632, 3, 1040, 6, 66],\n",
       " [32, 10, 26, 317, 632, 3, 1040, 6, 66, 12],\n",
       " [19, 10],\n",
       " [19, 10, 1],\n",
       " [19, 10, 1, 633],\n",
       " [19, 10, 1, 633, 2],\n",
       " [19, 10, 1, 633, 2, 634],\n",
       " [19, 10, 1, 633, 2, 634, 4],\n",
       " [19, 10, 1, 633, 2, 634, 4, 5],\n",
       " [19, 10, 1, 633, 2, 634, 4, 5, 1041],\n",
       " [18, 1042],\n",
       " [18, 1042, 120],\n",
       " [18, 1042, 120, 252],\n",
       " [18, 1042, 120, 252, 1043],\n",
       " [18, 1042, 120, 252, 1043, 3],\n",
       " [18, 1042, 120, 252, 1043, 3, 30],\n",
       " [18, 1042, 120, 252, 1043, 3, 30, 202],\n",
       " [63, 41],\n",
       " [63, 41, 69],\n",
       " [63, 41, 69, 359],\n",
       " [63, 41, 69, 359, 129],\n",
       " [63, 41, 69, 359, 129, 125],\n",
       " [63, 41, 69, 359, 129, 125, 20],\n",
       " [63, 41, 69, 359, 129, 125, 20, 25],\n",
       " [63, 41, 69, 359, 129, 125, 20, 25, 11],\n",
       " [63, 41, 69, 359, 129, 125, 20, 25, 11, 1044],\n",
       " [88, 18],\n",
       " [88, 18, 279],\n",
       " [88, 18, 279, 1045],\n",
       " [88, 18, 279, 1045, 2],\n",
       " [88, 18, 279, 1045, 2, 40],\n",
       " [88, 18, 279, 1045, 2, 40, 1046],\n",
       " [88, 18, 279, 1045, 2, 40, 1046, 163],\n",
       " [24, 635],\n",
       " [24, 635, 1047],\n",
       " [24, 635, 1047, 1],\n",
       " [24, 635, 1047, 1, 458],\n",
       " [24, 635, 1047, 1, 458, 4],\n",
       " [24, 635, 1047, 1, 458, 4, 1],\n",
       " [24, 635, 1047, 1, 458, 4, 1, 636],\n",
       " [2, 88],\n",
       " [2, 88, 94],\n",
       " [2, 88, 94, 1048],\n",
       " [2, 88, 94, 1048, 364],\n",
       " [2, 88, 94, 1048, 364, 4],\n",
       " [2, 88, 94, 1048, 364, 4, 1049],\n",
       " [2, 88, 94, 1048, 364, 4, 1049, 459],\n",
       " [2, 1050],\n",
       " [2, 1050, 1051],\n",
       " [2, 1050, 1051, 22],\n",
       " [2, 1050, 1051, 22, 1052],\n",
       " [2, 1050, 1051, 22, 1052, 4],\n",
       " [2, 1050, 1051, 22, 1052, 4, 1053],\n",
       " [88, 94],\n",
       " [88, 94, 1054],\n",
       " [88, 94, 1054, 4],\n",
       " [88, 94, 1054, 4, 1055],\n",
       " [88, 94, 1054, 4, 1055, 1056],\n",
       " [88, 94, 1054, 4, 1055, 1056, 156],\n",
       " [88, 94, 1054, 4, 1055, 1056, 156, 1057],\n",
       " [88, 94, 1054, 4, 1055, 1056, 156, 1057, 1058],\n",
       " [1059, 12],\n",
       " [1059, 12, 1060],\n",
       " [1059, 12, 1060, 1],\n",
       " [1059, 12, 1060, 1, 1061],\n",
       " [1059, 12, 1060, 1, 1061, 58],\n",
       " [1059, 12, 1060, 1, 1061, 58, 1],\n",
       " [1059, 12, 1060, 1, 1061, 58, 1, 1062],\n",
       " [26, 131],\n",
       " [26, 131, 28],\n",
       " [26, 131, 28, 637],\n",
       " [26, 131, 28, 637, 11],\n",
       " [26, 131, 28, 637, 11, 18],\n",
       " [26, 131, 28, 637, 11, 18, 1063],\n",
       " [26, 131, 28, 637, 11, 18, 1063, 140],\n",
       " [203, 108],\n",
       " [203, 108, 1],\n",
       " [203, 108, 1, 73],\n",
       " [203, 108, 1, 73, 638],\n",
       " [203, 108, 1, 73, 638, 1064],\n",
       " [203, 108, 1, 73, 638, 1064, 16],\n",
       " [203, 108, 1, 73, 638, 1064, 16, 1],\n",
       " [203, 108, 1, 73, 638, 1064, 16, 1, 144],\n",
       " [117, 318],\n",
       " [117, 318, 11],\n",
       " [117, 318, 11, 167],\n",
       " [117, 318, 11, 167, 1065],\n",
       " [117, 318, 11, 167, 1065, 20],\n",
       " [32, 11],\n",
       " [32, 11, 167],\n",
       " [32, 11, 167, 6],\n",
       " [47, 639],\n",
       " [47, 639, 1],\n",
       " [47, 639, 1, 1066],\n",
       " [47, 639, 1, 1066, 285],\n",
       " [47, 639, 1, 1066, 285, 24],\n",
       " [47, 639, 1, 1066, 285, 24, 30],\n",
       " [47, 639, 1, 1066, 285, 24, 30, 278],\n",
       " [47, 639, 1, 1066, 285, 24, 30, 278, 39],\n",
       " [156, 1067],\n",
       " [156, 1067, 181],\n",
       " [156, 1067, 181, 19],\n",
       " [156, 1067, 181, 19, 69],\n",
       " [156, 1067, 181, 19, 69, 446],\n",
       " [156, 1067, 181, 19, 69, 446, 3],\n",
       " [156, 1067, 181, 19, 69, 446, 3, 92],\n",
       " [56, 23],\n",
       " [56, 23, 7],\n",
       " [56, 23, 7, 66],\n",
       " [56, 23, 7, 66, 38],\n",
       " [56, 23, 7, 66, 38, 253],\n",
       " [56, 23, 7, 66, 38, 253, 4],\n",
       " [56, 23, 7, 66, 38, 253, 4, 365],\n",
       " [1068, 1069],\n",
       " [1068, 1069, 43],\n",
       " [1068, 1069, 43, 38],\n",
       " [1068, 1069, 43, 38, 8],\n",
       " [1068, 1069, 43, 38, 8, 40],\n",
       " [1068, 1069, 43, 38, 8, 40, 1070],\n",
       " [1068, 1069, 43, 38, 8, 40, 1070, 1071],\n",
       " [1072, 3],\n",
       " [1072, 3, 1],\n",
       " [1072, 3, 1, 1073],\n",
       " [1072, 3, 1, 1073, 10],\n",
       " [1072, 3, 1, 1073, 10, 74],\n",
       " [1072, 3, 1, 1073, 10, 74, 30],\n",
       " [1072, 3, 1, 1073, 10, 74, 30, 460],\n",
       " [1072, 3, 1, 1073, 10, 74, 30, 460, 52],\n",
       " [22, 24],\n",
       " [22, 24, 18],\n",
       " [22, 24, 18, 1074],\n",
       " [22, 24, 18, 1074, 4],\n",
       " [22, 24, 18, 1074, 4, 30],\n",
       " [22, 24, 18, 1074, 4, 30, 461],\n",
       " [22, 24, 18, 1074, 4, 30, 461, 254],\n",
       " [22, 24, 18, 1074, 4, 30, 461, 254, 1075],\n",
       " [22, 24, 18, 1074, 4, 30, 461, 254, 1075, 29],\n",
       " [65, 1076],\n",
       " [65, 1076, 18],\n",
       " [65, 1076, 18, 253],\n",
       " [65, 1076, 18, 253, 117],\n",
       " [65, 1076, 18, 253, 117, 38],\n",
       " [65, 1076, 18, 253, 117, 38, 8],\n",
       " [65, 1076, 18, 253, 117, 38, 8, 1077],\n",
       " [65, 1076, 18, 253, 117, 38, 8, 1077, 1078],\n",
       " [54, 1079],\n",
       " [54, 1079, 38],\n",
       " [54, 1079, 38, 462],\n",
       " [54, 1079, 38, 462, 2],\n",
       " [54, 1079, 38, 462, 2, 1080],\n",
       " [65, 1081],\n",
       " [65, 1081, 16],\n",
       " [65, 1081, 16, 14],\n",
       " [65, 1081, 16, 14, 182],\n",
       " [65, 1081, 16, 14, 182, 36],\n",
       " [65, 1081, 16, 14, 182, 36, 183],\n",
       " [65, 1081, 16, 14, 182, 36, 183, 14],\n",
       " [65, 1081, 16, 14, 182, 36, 183, 14, 463],\n",
       " [74, 25],\n",
       " [74, 25, 464],\n",
       " [74, 25, 464, 1082],\n",
       " [74, 25, 464, 1082, 43],\n",
       " [74, 25, 464, 1082, 43, 3],\n",
       " [74, 25, 464, 1082, 43, 3, 1],\n",
       " [74, 25, 464, 1082, 43, 3, 1, 1083],\n",
       " [179, 1],\n",
       " [179, 1, 74],\n",
       " [179, 1, 74, 8],\n",
       " [179, 1, 74, 8, 1084],\n",
       " [179, 1, 74, 8, 1084, 1085],\n",
       " [56, 1086],\n",
       " [56, 1086, 38],\n",
       " [56, 1086, 38, 30],\n",
       " [56, 1086, 38, 30, 39],\n",
       " [56, 1086, 38, 30, 39, 74],\n",
       " [56, 1086, 38, 30, 39, 74, 99],\n",
       " [56, 1086, 38, 30, 39, 74, 99, 640],\n",
       " [3, 1],\n",
       " [3, 1, 1087],\n",
       " [3, 1, 1087, 4],\n",
       " [3, 1, 1087, 4, 253],\n",
       " [99, 25],\n",
       " [99, 25, 641],\n",
       " [99, 25, 641, 1088],\n",
       " [99, 25, 641, 1088, 23],\n",
       " [99, 25, 641, 1088, 23, 38],\n",
       " [99, 25, 641, 1088, 23, 38, 1],\n",
       " [99, 25, 641, 1088, 23, 38, 1, 279],\n",
       " [99, 25, 641, 1088, 23, 38, 1, 279, 1089],\n",
       " [2, 1090],\n",
       " [2, 1090, 4],\n",
       " [2, 1090, 4, 1],\n",
       " [2, 1090, 4, 1, 1091],\n",
       " [2, 1090, 4, 1, 1091, 1092],\n",
       " [14, 319],\n",
       " [14, 319, 3],\n",
       " [14, 319, 3, 52],\n",
       " [14, 319, 3, 52, 69],\n",
       " [14, 319, 3, 52, 69, 121],\n",
       " [14, 319, 3, 52, 69, 121, 286],\n",
       " [14, 319, 3, 52, 69, 121, 286, 253],\n",
       " [4, 1093],\n",
       " [4, 1093, 1094],\n",
       " [4, 1093, 1094, 642],\n",
       " [4, 1093, 1094, 642, 2],\n",
       " [4, 1093, 1094, 642, 2, 465],\n",
       " [76, 10],\n",
       " [76, 10, 1],\n",
       " [76, 10, 1, 1095],\n",
       " [76, 10, 1, 1095, 4],\n",
       " [76, 10, 1, 1095, 4, 365],\n",
       " [76, 10, 1, 1095, 4, 365, 145],\n",
       " [76, 10, 1, 1095, 4, 365, 145, 2],\n",
       " [76, 10, 1, 1095, 4, 365, 145, 2, 48],\n",
       " [1096, 126],\n",
       " [1096, 126, 8],\n",
       " [1096, 126, 8, 320],\n",
       " [1096, 126, 8, 320, 4],\n",
       " [1096, 126, 8, 320, 4, 1097],\n",
       " [1096, 126, 8, 320, 4, 1097, 1098],\n",
       " [22, 1099],\n",
       " [22, 1099, 2],\n",
       " [22, 1099, 2, 1100],\n",
       " [22, 1099, 2, 1100, 3],\n",
       " [22, 1099, 2, 1100, 3, 120],\n",
       " [22, 1099, 2, 1100, 3, 120, 643],\n",
       " [11, 76],\n",
       " [11, 76, 8],\n",
       " [11, 76, 8, 1101],\n",
       " [11, 76, 8, 1101, 466],\n",
       " [11, 76, 8, 1101, 466, 74],\n",
       " [11, 76, 8, 1101, 466, 74, 15],\n",
       " [11, 76, 8, 1101, 466, 74, 15, 34],\n",
       " [11, 76, 8, 1101, 466, 74, 15, 34, 255],\n",
       " [2, 9],\n",
       " [2, 9, 203],\n",
       " [2, 9, 203, 54],\n",
       " [2, 9, 203, 54, 449],\n",
       " [2, 9, 203, 54, 449, 467],\n",
       " [2, 9, 203, 54, 449, 467, 30],\n",
       " [2, 9, 203, 54, 449, 467, 30, 202],\n",
       " [19, 3],\n",
       " [19, 3, 1102],\n",
       " [19, 3, 1102, 4],\n",
       " [19, 3, 1102, 4, 92],\n",
       " [19, 3, 1102, 4, 92, 38],\n",
       " [19, 3, 1102, 4, 92, 38, 1103],\n",
       " [19, 3, 1102, 4, 92, 38, 1103, 229],\n",
       " [2, 1104],\n",
       " [2, 1104, 1105],\n",
       " [2, 1104, 1105, 183],\n",
       " [2, 1104, 1105, 183, 1106],\n",
       " [2, 1104, 1105, 183, 1106, 463],\n",
       " [24, 38],\n",
       " [24, 38, 14],\n",
       " [24, 38, 14, 82],\n",
       " [24, 38, 14, 82, 287],\n",
       " [24, 38, 14, 82, 287, 2],\n",
       " [24, 38, 14, 82, 287, 2, 18],\n",
       " [24, 38, 14, 82, 287, 2, 18, 6],\n",
       " [24, 38, 14, 82, 287, 2, 18, 6, 109],\n",
       " [24, 38, 14, 82, 287, 2, 18, 6, 109, 9],\n",
       " [15, 1],\n",
       " [15, 1, 468],\n",
       " [15, 1, 468, 644],\n",
       " [15, 1, 468, 644, 4],\n",
       " [15, 1, 468, 644, 4, 30],\n",
       " [15, 1, 468, 644, 4, 30, 1107],\n",
       " [1, 645],\n",
       " [1, 645, 4],\n",
       " [1, 645, 4, 18],\n",
       " [1, 645, 4, 18, 30],\n",
       " [1, 645, 4, 18, 30, 163],\n",
       " [1, 645, 4, 18, 30, 163, 2],\n",
       " [1, 645, 4, 18, 30, 163, 2, 1],\n",
       " [1, 645, 4, 18, 30, 163, 2, 1, 646],\n",
       " [1, 645, 4, 18, 30, 163, 2, 1, 646, 133],\n",
       " [4, 18],\n",
       " [4, 18, 647],\n",
       " [4, 18, 647, 140],\n",
       " [4, 18, 647, 140, 2],\n",
       " [4, 18, 647, 140, 2, 1108],\n",
       " [4, 18, 647, 140, 2, 1108, 10],\n",
       " [4, 18, 647, 140, 2, 1108, 10, 1],\n",
       " [4, 18, 647, 140, 2, 1108, 10, 1, 636],\n",
       " [70, 113],\n",
       " [70, 113, 123],\n",
       " [19, 648],\n",
       " [19, 648, 1109],\n",
       " [19, 648, 1109, 649],\n",
       " [19, 648, 1109, 649, 112],\n",
       " [19, 648, 1109, 649, 112, 9],\n",
       " [19, 648, 1109, 649, 112, 9, 154],\n",
       " [19, 648, 1109, 649, 112, 9, 154, 123],\n",
       " [89, 650],\n",
       " [89, 650, 9],\n",
       " [89, 650, 9, 134],\n",
       " [89, 650, 9, 134, 9],\n",
       " [89, 650, 9, 134, 9, 1110],\n",
       " [89, 650, 9, 134, 9, 1110, 20],\n",
       " [89, 650, 9, 134, 9, 1110, 20, 283],\n",
       " [89, 650, 9, 134, 9, 1110, 20, 283, 1111],\n",
       " [45, 55],\n",
       " [45, 55, 140],\n",
       " [45, 55, 140, 157],\n",
       " [45, 55, 140, 157, 469],\n",
       " [45, 55, 140, 157, 469, 37],\n",
       " [45, 55, 140, 157, 469, 37, 230],\n",
       " [45, 55, 140, 157, 469, 37, 230, 4],\n",
       " [45, 55, 140, 157, 469, 37, 230, 4, 288],\n",
       " [57, 3],\n",
       " [57, 3, 20],\n",
       " [57, 3, 20, 45],\n",
       " [57, 3, 20, 45, 48],\n",
       " [57, 3, 20, 45, 48, 28],\n",
       " [57, 3, 20, 45, 48, 28, 157],\n",
       " [57, 3, 20, 45, 48, 28, 157, 41],\n",
       " [57, 3, 20, 45, 48, 28, 157, 41, 152],\n",
       " [57, 3, 20, 45, 48, 28, 157, 41, 152, 3],\n",
       " [57, 3, 20, 45, 48, 28, 157, 41, 152, 3, 28],\n",
       " [57, 3, 20, 45, 48, 28, 157, 41, 152, 3, 28, 321],\n",
       " [11, 77],\n",
       " [11, 77, 3],\n",
       " [11, 77, 3, 71],\n",
       " [11, 77, 3, 71, 72],\n",
       " [11, 77, 3, 71, 72, 651],\n",
       " [11, 77, 3, 71, 72, 651, 2],\n",
       " [11, 77, 3, 71, 72, 651, 2, 289],\n",
       " [11, 77, 3, 71, 72, 651, 2, 289, 3],\n",
       " [11, 77, 3, 71, 72, 651, 2, 289, 3, 20],\n",
       " [11, 77, 3, 71, 72, 651, 2, 289, 3, 20, 470],\n",
       " [11, 77, 3, 71, 72, 651, 2, 289, 3, 20, 470, 3],\n",
       " [11, 77, 3, 71, 72, 651, 2, 289, 3, 20, 470, 3, 20],\n",
       " [45, 55],\n",
       " [45, 55, 180],\n",
       " [45, 55, 180, 1112],\n",
       " [45, 55, 180, 1112, 3],\n",
       " [45, 55, 180, 1112, 3, 46],\n",
       " [45, 55, 180, 1112, 3, 46, 1113],\n",
       " [45, 55, 180, 1112, 3, 46, 1113, 652],\n",
       " [74, 653],\n",
       " [74, 653, 1114],\n",
       " [74, 653, 1114, 77],\n",
       " [74, 653, 1114, 77, 1115],\n",
       " [74, 653, 1114, 77, 1115, 67],\n",
       " [74, 653, 1114, 77, 1115, 67, 57],\n",
       " [37, 45],\n",
       " [37, 45, 55],\n",
       " [37, 45, 55, 140],\n",
       " [37, 45, 55, 140, 126],\n",
       " [37, 45, 55, 140, 126, 1116],\n",
       " [37, 45, 55, 140, 126, 1116, 10],\n",
       " [37, 45, 55, 140, 126, 1116, 10, 46],\n",
       " [37, 45, 55, 140, 126, 1116, 10, 46, 182],\n",
       " [1117, 366],\n",
       " [1117, 366, 10],\n",
       " [1117, 366, 10, 1],\n",
       " [1117, 366, 10, 1, 1118],\n",
       " [1117, 366, 10, 1, 1118, 4],\n",
       " [1117, 366, 10, 1, 1118, 4, 204],\n",
       " [22, 74],\n",
       " [22, 74, 53],\n",
       " [22, 74, 53, 84],\n",
       " [22, 74, 53, 84, 7],\n",
       " [22, 74, 53, 84, 7, 654],\n",
       " [22, 74, 53, 84, 7, 654, 290],\n",
       " [22, 74, 53, 84, 7, 654, 290, 256],\n",
       " [22, 74, 53, 84, 7, 654, 290, 256, 10],\n",
       " [22, 74, 53, 84, 7, 654, 290, 256, 10, 184],\n",
       " [57, 4],\n",
       " [57, 4, 9],\n",
       " [57, 4, 9, 283],\n",
       " [57, 4, 9, 283, 2],\n",
       " [57, 4, 9, 283, 2, 57],\n",
       " [57, 4, 9, 283, 2, 57, 1119],\n",
       " [57, 4, 9, 283, 2, 57, 1119, 9],\n",
       " [57, 4, 9, 283, 2, 57, 1119, 9, 177],\n",
       " [63, 44],\n",
       " [63, 44, 6],\n",
       " [63, 44, 6, 655],\n",
       " [63, 44, 6, 655, 47],\n",
       " [63, 44, 6, 655, 47, 9],\n",
       " [63, 44, 6, 655, 47, 9, 16],\n",
       " [63, 44, 6, 655, 47, 9, 16, 5],\n",
       " [63, 44, 6, 655, 47, 9, 16, 5, 1120],\n",
       " [32, 72],\n",
       " [32, 72, 45],\n",
       " [32, 72, 45, 9],\n",
       " [32, 72, 45, 9, 42],\n",
       " [32, 72, 45, 9, 42, 12],\n",
       " [32, 72, 45, 9, 42, 12, 276],\n",
       " [176, 79],\n",
       " [176, 79, 145],\n",
       " [32, 79],\n",
       " [32, 79, 145],\n",
       " [63, 79],\n",
       " [63, 79, 284],\n",
       " [199, 113],\n",
       " [33, 72],\n",
       " [33, 72, 9],\n",
       " [33, 72, 9, 656],\n",
       " [33, 72, 9, 656, 231],\n",
       " [33, 72, 9, 656, 231, 24],\n",
       " [33, 72, 9, 656, 231, 24, 657],\n",
       " [3, 471],\n",
       " [3, 471, 9],\n",
       " [3, 471, 9, 1],\n",
       " [3, 471, 9, 1, 257],\n",
       " [3, 471, 9, 1, 257, 4],\n",
       " [3, 471, 9, 1, 257, 4, 658],\n",
       " [22, 9],\n",
       " [22, 9, 15],\n",
       " [22, 9, 15, 23],\n",
       " [22, 9, 15, 23, 1],\n",
       " [22, 9, 15, 23, 1, 205],\n",
       " [22, 9, 15, 23, 1, 205, 1121],\n",
       " [2, 30],\n",
       " [2, 30, 1122],\n",
       " [2, 30, 1122, 659],\n",
       " [2, 30, 1122, 659, 660],\n",
       " [2, 30, 1122, 659, 660, 1123],\n",
       " [176, 9],\n",
       " [176, 9, 56],\n",
       " [176, 9, 56, 185],\n",
       " [176, 9, 56, 185, 3],\n",
       " [176, 9, 56, 185, 3, 57],\n",
       " [176, 9, 56, 185, 3, 57, 111],\n",
       " [176, 9, 56, 185, 3, 57, 111, 1],\n",
       " [176, 9, 56, 185, 3, 57, 111, 1, 367],\n",
       " [176, 9, 56, 185, 3, 57, 111, 1, 367, 661],\n",
       " [32, 2],\n",
       " [32, 2, 31],\n",
       " [32, 2, 31, 9],\n",
       " [32, 2, 31, 9, 1124],\n",
       " [32, 2, 31, 9, 1124, 49],\n",
       " [32, 2, 31, 9, 1124, 49, 8],\n",
       " [32, 2, 31, 9, 1124, 49, 8, 368],\n",
       " [32, 2, 31, 9, 1124, 49, 8, 368, 152],\n",
       " [90, 8],\n",
       " [90, 8, 1125],\n",
       " [90, 8, 1125, 1126],\n",
       " [90, 8, 1125, 1126, 6],\n",
       " [90, 8, 1125, 1126, 6, 27],\n",
       " [90, 8, 1125, 1126, 6, 27, 258],\n",
       " [1, 367],\n",
       " [1, 367, 11],\n",
       " [1, 367, 11, 15],\n",
       " [1, 367, 11, 15, 1],\n",
       " [1, 367, 11, 15, 1, 662],\n",
       " [1, 367, 11, 15, 1, 662, 3],\n",
       " [1, 367, 11, 15, 1, 662, 3, 1],\n",
       " [1, 367, 11, 15, 1, 662, 3, 1, 144],\n",
       " [203, 16],\n",
       " [203, 16, 14],\n",
       " [203, 16, 14, 1127],\n",
       " [203, 16, 14, 1127, 2],\n",
       " [203, 16, 14, 1127, 2, 1128],\n",
       " [203, 16, 14, 1127, 2, 1128, 1129],\n",
       " [203, 16, 14, 1127, 2, 1128, 1129, 663],\n",
       " [1130, 1],\n",
       " [1130, 1, 124],\n",
       " [1130, 1, 124, 4],\n",
       " [1130, 1, 124, 4, 144],\n",
       " [1130, 1, 124, 4, 144, 2],\n",
       " [1130, 1, 124, 4, 144, 2, 47],\n",
       " [1130, 1, 124, 4, 144, 2, 47, 14],\n",
       " [1130, 1, 124, 4, 144, 2, 47, 14, 1131],\n",
       " [664, 10],\n",
       " [664, 10, 665],\n",
       " [664, 10, 665, 37],\n",
       " [664, 10, 665, 37, 291],\n",
       " [664, 10, 665, 37, 291, 10],\n",
       " [664, 10, 665, 37, 291, 10, 204],\n",
       " [664, 10, 665, 37, 291, 10, 204, 37],\n",
       " [664, 10, 665, 37, 291, 10, 204, 37, 205],\n",
       " [143, 1132],\n",
       " [143, 1132, 2],\n",
       " [143, 1132, 2, 1133],\n",
       " [143, 1132, 2, 1133, 206],\n",
       " [143, 1132, 2, 1133, 206, 1134],\n",
       " [3, 14],\n",
       " [3, 14, 1135],\n",
       " [3, 14, 1135, 2],\n",
       " [3, 14, 1135, 2, 4],\n",
       " [3, 14, 1135, 2, 4, 1],\n",
       " [3, 14, 1135, 2, 4, 1, 322],\n",
       " [3, 14, 1135, 2, 4, 1, 322, 369],\n",
       " [18, 1136],\n",
       " [18, 1136, 1137],\n",
       " [18, 1136, 1137, 153],\n",
       " [18, 1136, 1137, 153, 1138],\n",
       " [63, 9],\n",
       " [63, 9, 1139],\n",
       " [63, 9, 1139, 43],\n",
       " [63, 9, 1139, 43, 1],\n",
       " [63, 9, 1139, 43, 1, 1140],\n",
       " [63, 9, 1139, 43, 1, 1140, 4],\n",
       " [63, 9, 1139, 43, 1, 1140, 4, 1],\n",
       " [63, 9, 1139, 43, 1, 1140, 4, 1, 367],\n",
       " [120, 472],\n",
       " [120, 472, 11],\n",
       " [120, 472, 11, 232],\n",
       " [120, 472, 11, 232, 370],\n",
       " [120, 472, 11, 232, 370, 11],\n",
       " [120, 472, 11, 232, 370, 11, 323],\n",
       " [120, 472, 11, 232, 370, 11, 323, 154],\n",
       " [371, 30],\n",
       " [371, 30, 1141],\n",
       " [371, 30, 1141, 1142],\n",
       " [371, 30, 1141, 1142, 15],\n",
       " [371, 30, 1141, 1142, 15, 1143],\n",
       " [1, 666],\n",
       " [1, 666, 4],\n",
       " [1, 666, 4, 1144],\n",
       " [1, 666, 4, 1144, 1145],\n",
       " [1, 666, 4, 1144, 1145, 36],\n",
       " [1, 666, 4, 1144, 1145, 36, 73],\n",
       " [1, 666, 4, 1144, 1145, 36, 73, 222],\n",
       " [2, 31],\n",
       " [2, 31, 53],\n",
       " [2, 31, 53, 84],\n",
       " [2, 31, 53, 84, 34],\n",
       " [2, 31, 53, 84, 34, 206],\n",
       " [2, 31, 53, 84, 34, 206, 167],\n",
       " [2, 31, 53, 84, 34, 206, 167, 256],\n",
       " [2, 31, 53, 84, 34, 206, 167, 256, 1146],\n",
       " [1, 450],\n",
       " [1, 450, 35],\n",
       " [1, 450, 35, 667],\n",
       " [1, 450, 35, 667, 31],\n",
       " [1, 450, 35, 667, 31, 34],\n",
       " [1, 450, 35, 667, 31, 34, 1147],\n",
       " ...]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create input sequences\n",
    "input_sequence=[]\n",
    "for line in text.split('\\n'):\n",
    "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_sequence=token_list[:i+1]\n",
    "        input_sequence.append(n_gram_sequence)\n",
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13e3bc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pad Sequences\n",
    "max_sequence_len= max([len(x) for x in input_sequence])\n",
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "932d7e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    1,  611],\n",
       "       [   0,    0,    0, ...,    1,  611,    4],\n",
       "       [   0,    0,    0, ...,  611,    4,   52],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,   39,  387],\n",
       "       [   0,    0,    0, ...,   39,  387,  673],\n",
       "       [   0,    0,    0, ...,  387,  673, 2711]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence= np.array(pad_sequences(input_sequence, maxlen=max_sequence_len, padding='pre'))\n",
    "#input_sequence=input_sequence[:35000]\n",
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "85107403",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create predictors and labels\n",
    "import tensorflow as tf\n",
    "\n",
    "x,y= input_sequence[:, :-1], input_sequence[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f01e8b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   1],\n",
       "       [  0,   0,   0, ...,   0,   1, 611],\n",
       "       [  0,   0,   0, ...,   1, 611,   4],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,  39],\n",
       "       [  0,   0,   0, ...,   0,  39, 387],\n",
       "       [  0,   0,   0, ...,  39, 387, 673]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0819eb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 611,    4,   52, ...,  387,  673, 2711])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b9fac5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fab6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dda55d",
   "metadata": {},
   "source": [
    "## Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "09192763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 13, 100)           271200    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 13, 150)           150600    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 150)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2712)              273912    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 796112 (3.04 MB)\n",
      "Trainable params: 796112 (3.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM, Dense, Dropout\n",
    "\n",
    "## Define model\n",
    "model= Sequential()\n",
    "model.add(Embedding(total_words,100,input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words,activation=\"softmax\"))\n",
    "\n",
    "## Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac76d17",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d4eb16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "276/276 [==============================] - 6s 21ms/step - loss: 3.6367 - accuracy: 0.2313 - val_loss: 9.3513 - val_accuracy: 0.0498\n",
      "Epoch 2/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 3.5775 - accuracy: 0.2362 - val_loss: 9.4267 - val_accuracy: 0.0534\n",
      "Epoch 3/100\n",
      "276/276 [==============================] - 6s 23ms/step - loss: 3.5236 - accuracy: 0.2481 - val_loss: 9.5278 - val_accuracy: 0.0530\n",
      "Epoch 4/100\n",
      "276/276 [==============================] - 6s 23ms/step - loss: 3.4674 - accuracy: 0.2528 - val_loss: 9.5972 - val_accuracy: 0.0507\n",
      "Epoch 5/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 3.4129 - accuracy: 0.2655 - val_loss: 9.7210 - val_accuracy: 0.0539\n",
      "Epoch 6/100\n",
      "276/276 [==============================] - 6s 23ms/step - loss: 3.3663 - accuracy: 0.2676 - val_loss: 9.7843 - val_accuracy: 0.0489\n",
      "Epoch 7/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 3.3123 - accuracy: 0.2832 - val_loss: 9.8626 - val_accuracy: 0.0516\n",
      "Epoch 8/100\n",
      "276/276 [==============================] - 6s 23ms/step - loss: 3.2679 - accuracy: 0.2908 - val_loss: 9.9605 - val_accuracy: 0.0498\n",
      "Epoch 9/100\n",
      "276/276 [==============================] - 6s 24ms/step - loss: 3.2186 - accuracy: 0.3024 - val_loss: 10.0221 - val_accuracy: 0.0539\n",
      "Epoch 10/100\n",
      "276/276 [==============================] - 8s 28ms/step - loss: 3.1769 - accuracy: 0.3101 - val_loss: 10.0999 - val_accuracy: 0.0462\n",
      "Epoch 11/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 3.1335 - accuracy: 0.3169 - val_loss: 10.1529 - val_accuracy: 0.0525\n",
      "Epoch 12/100\n",
      "276/276 [==============================] - 6s 23ms/step - loss: 3.0833 - accuracy: 0.3307 - val_loss: 10.2600 - val_accuracy: 0.0494\n",
      "Epoch 13/100\n",
      "276/276 [==============================] - 6s 23ms/step - loss: 3.0521 - accuracy: 0.3345 - val_loss: 10.3325 - val_accuracy: 0.0516\n",
      "Epoch 14/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 3.0145 - accuracy: 0.3368 - val_loss: 10.4167 - val_accuracy: 0.0476\n",
      "Epoch 15/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.9622 - accuracy: 0.3491 - val_loss: 10.4764 - val_accuracy: 0.0534\n",
      "Epoch 16/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.9232 - accuracy: 0.3559 - val_loss: 10.5558 - val_accuracy: 0.0525\n",
      "Epoch 17/100\n",
      "276/276 [==============================] - 6s 24ms/step - loss: 2.8873 - accuracy: 0.3645 - val_loss: 10.6495 - val_accuracy: 0.0462\n",
      "Epoch 18/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.8470 - accuracy: 0.3711 - val_loss: 10.6825 - val_accuracy: 0.0466\n",
      "Epoch 19/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.8090 - accuracy: 0.3795 - val_loss: 10.8160 - val_accuracy: 0.0462\n",
      "Epoch 20/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.7750 - accuracy: 0.3859 - val_loss: 10.8857 - val_accuracy: 0.0485\n",
      "Epoch 21/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.7361 - accuracy: 0.3928 - val_loss: 10.9333 - val_accuracy: 0.0494\n",
      "Epoch 22/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.7066 - accuracy: 0.4003 - val_loss: 10.9779 - val_accuracy: 0.0471\n",
      "Epoch 23/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.6710 - accuracy: 0.4104 - val_loss: 11.0604 - val_accuracy: 0.0480\n",
      "Epoch 24/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 2.6352 - accuracy: 0.4103 - val_loss: 11.1548 - val_accuracy: 0.0448\n",
      "Epoch 25/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.6035 - accuracy: 0.4206 - val_loss: 11.1934 - val_accuracy: 0.0430\n",
      "Epoch 26/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.5730 - accuracy: 0.4268 - val_loss: 11.2753 - val_accuracy: 0.0480\n",
      "Epoch 27/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.5356 - accuracy: 0.4372 - val_loss: 11.3319 - val_accuracy: 0.0480\n",
      "Epoch 28/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.5161 - accuracy: 0.4435 - val_loss: 11.3550 - val_accuracy: 0.0466\n",
      "Epoch 29/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.4839 - accuracy: 0.4483 - val_loss: 11.4533 - val_accuracy: 0.0453\n",
      "Epoch 30/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.4528 - accuracy: 0.4582 - val_loss: 11.5194 - val_accuracy: 0.0462\n",
      "Epoch 31/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.4171 - accuracy: 0.4616 - val_loss: 11.5569 - val_accuracy: 0.0466\n",
      "Epoch 32/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.3956 - accuracy: 0.4688 - val_loss: 11.6231 - val_accuracy: 0.0489\n",
      "Epoch 33/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.3629 - accuracy: 0.4679 - val_loss: 11.6737 - val_accuracy: 0.0448\n",
      "Epoch 34/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.3396 - accuracy: 0.4759 - val_loss: 11.8003 - val_accuracy: 0.0471\n",
      "Epoch 35/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.3157 - accuracy: 0.4820 - val_loss: 11.7997 - val_accuracy: 0.0462\n",
      "Epoch 36/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.2789 - accuracy: 0.4888 - val_loss: 11.8824 - val_accuracy: 0.0457\n",
      "Epoch 37/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 2.2632 - accuracy: 0.4952 - val_loss: 11.9257 - val_accuracy: 0.0444\n",
      "Epoch 38/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 2.2354 - accuracy: 0.5035 - val_loss: 11.9858 - val_accuracy: 0.0426\n",
      "Epoch 39/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.2051 - accuracy: 0.5072 - val_loss: 12.0408 - val_accuracy: 0.0485\n",
      "Epoch 40/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.1788 - accuracy: 0.5126 - val_loss: 12.1370 - val_accuracy: 0.0471\n",
      "Epoch 41/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.1560 - accuracy: 0.5089 - val_loss: 12.1528 - val_accuracy: 0.0421\n",
      "Epoch 42/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.1372 - accuracy: 0.5193 - val_loss: 12.1870 - val_accuracy: 0.0466\n",
      "Epoch 43/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 2.1127 - accuracy: 0.5214 - val_loss: 12.2692 - val_accuracy: 0.0453\n",
      "Epoch 44/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.0870 - accuracy: 0.5292 - val_loss: 12.3066 - val_accuracy: 0.0476\n",
      "Epoch 45/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.0654 - accuracy: 0.5366 - val_loss: 12.3768 - val_accuracy: 0.0439\n",
      "Epoch 46/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 2.0511 - accuracy: 0.5384 - val_loss: 12.4147 - val_accuracy: 0.0457\n",
      "Epoch 47/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 2.0242 - accuracy: 0.5435 - val_loss: 12.4300 - val_accuracy: 0.0457\n",
      "Epoch 48/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 2.0067 - accuracy: 0.5433 - val_loss: 12.5038 - val_accuracy: 0.0453\n",
      "Epoch 49/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.9730 - accuracy: 0.5543 - val_loss: 12.5668 - val_accuracy: 0.0439\n",
      "Epoch 50/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.9448 - accuracy: 0.5615 - val_loss: 12.5966 - val_accuracy: 0.0462\n",
      "Epoch 51/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.9404 - accuracy: 0.5603 - val_loss: 12.6605 - val_accuracy: 0.0457\n",
      "Epoch 52/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.9119 - accuracy: 0.5698 - val_loss: 12.7495 - val_accuracy: 0.0435\n",
      "Epoch 53/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.8879 - accuracy: 0.5699 - val_loss: 12.8033 - val_accuracy: 0.0426\n",
      "Epoch 54/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.8677 - accuracy: 0.5780 - val_loss: 12.8070 - val_accuracy: 0.0435\n",
      "Epoch 55/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.8523 - accuracy: 0.5804 - val_loss: 12.8642 - val_accuracy: 0.0435\n",
      "Epoch 56/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.8356 - accuracy: 0.5809 - val_loss: 12.9066 - val_accuracy: 0.0435\n",
      "Epoch 57/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.8095 - accuracy: 0.5856 - val_loss: 13.0096 - val_accuracy: 0.0426\n",
      "Epoch 58/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.7936 - accuracy: 0.5948 - val_loss: 13.0204 - val_accuracy: 0.0439\n",
      "Epoch 59/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.7739 - accuracy: 0.6004 - val_loss: 13.0854 - val_accuracy: 0.0421\n",
      "Epoch 60/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.7482 - accuracy: 0.6016 - val_loss: 13.1209 - val_accuracy: 0.0448\n",
      "Epoch 61/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.7394 - accuracy: 0.6042 - val_loss: 13.1691 - val_accuracy: 0.0439\n",
      "Epoch 62/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.7224 - accuracy: 0.6095 - val_loss: 13.2301 - val_accuracy: 0.0457\n",
      "Epoch 63/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.7060 - accuracy: 0.6112 - val_loss: 13.2090 - val_accuracy: 0.0453\n",
      "Epoch 64/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.6781 - accuracy: 0.6181 - val_loss: 13.2727 - val_accuracy: 0.0448\n",
      "Epoch 65/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.6684 - accuracy: 0.6153 - val_loss: 13.3303 - val_accuracy: 0.0444\n",
      "Epoch 66/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.6422 - accuracy: 0.6261 - val_loss: 13.3485 - val_accuracy: 0.0417\n",
      "Epoch 67/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.6312 - accuracy: 0.6287 - val_loss: 13.4122 - val_accuracy: 0.0453\n",
      "Epoch 68/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.6087 - accuracy: 0.6345 - val_loss: 13.4218 - val_accuracy: 0.0453\n",
      "Epoch 69/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.5988 - accuracy: 0.6360 - val_loss: 13.5053 - val_accuracy: 0.0426\n",
      "Epoch 70/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.5881 - accuracy: 0.6413 - val_loss: 13.5577 - val_accuracy: 0.0426\n",
      "Epoch 71/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.5733 - accuracy: 0.6370 - val_loss: 13.5723 - val_accuracy: 0.0430\n",
      "Epoch 72/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.5487 - accuracy: 0.6492 - val_loss: 13.6553 - val_accuracy: 0.0453\n",
      "Epoch 73/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.5324 - accuracy: 0.6513 - val_loss: 13.6572 - val_accuracy: 0.0457\n",
      "Epoch 74/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.5232 - accuracy: 0.6478 - val_loss: 13.7158 - val_accuracy: 0.0453\n",
      "Epoch 75/100\n",
      "276/276 [==============================] - 7s 27ms/step - loss: 1.5019 - accuracy: 0.6579 - val_loss: 13.7400 - val_accuracy: 0.0430\n",
      "Epoch 76/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.4901 - accuracy: 0.6620 - val_loss: 13.7813 - val_accuracy: 0.0426\n",
      "Epoch 77/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.4771 - accuracy: 0.6631 - val_loss: 13.8622 - val_accuracy: 0.0462\n",
      "Epoch 78/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.4594 - accuracy: 0.6657 - val_loss: 13.8972 - val_accuracy: 0.0430\n",
      "Epoch 79/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.4426 - accuracy: 0.6686 - val_loss: 13.8921 - val_accuracy: 0.0453\n",
      "Epoch 80/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.4374 - accuracy: 0.6716 - val_loss: 13.9523 - val_accuracy: 0.0453\n",
      "Epoch 81/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.4129 - accuracy: 0.6783 - val_loss: 13.9688 - val_accuracy: 0.0453\n",
      "Epoch 82/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.4072 - accuracy: 0.6763 - val_loss: 14.0834 - val_accuracy: 0.0439\n",
      "Epoch 83/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.3971 - accuracy: 0.6808 - val_loss: 14.0675 - val_accuracy: 0.0448\n",
      "Epoch 84/100\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.3728 - accuracy: 0.6821 - val_loss: 14.1255 - val_accuracy: 0.0462\n",
      "Epoch 85/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.3649 - accuracy: 0.6863 - val_loss: 14.2186 - val_accuracy: 0.0494\n",
      "Epoch 86/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.3506 - accuracy: 0.6892 - val_loss: 14.2027 - val_accuracy: 0.0457\n",
      "Epoch 87/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.3361 - accuracy: 0.6931 - val_loss: 14.1963 - val_accuracy: 0.0444\n",
      "Epoch 88/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.3196 - accuracy: 0.6972 - val_loss: 14.2450 - val_accuracy: 0.0462\n",
      "Epoch 89/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.3143 - accuracy: 0.6951 - val_loss: 14.3180 - val_accuracy: 0.0448\n",
      "Epoch 90/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.3107 - accuracy: 0.6976 - val_loss: 14.3274 - val_accuracy: 0.0426\n",
      "Epoch 91/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.2946 - accuracy: 0.7004 - val_loss: 14.3872 - val_accuracy: 0.0412\n",
      "Epoch 92/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.2742 - accuracy: 0.7036 - val_loss: 14.4004 - val_accuracy: 0.0421\n",
      "Epoch 93/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.2678 - accuracy: 0.7079 - val_loss: 14.4598 - val_accuracy: 0.0439\n",
      "Epoch 94/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.2519 - accuracy: 0.7143 - val_loss: 14.4734 - val_accuracy: 0.0421\n",
      "Epoch 95/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.2396 - accuracy: 0.7108 - val_loss: 14.5213 - val_accuracy: 0.0412\n",
      "Epoch 96/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.2287 - accuracy: 0.7194 - val_loss: 14.5513 - val_accuracy: 0.0435\n",
      "Epoch 97/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.2217 - accuracy: 0.7181 - val_loss: 14.5770 - val_accuracy: 0.0421\n",
      "Epoch 98/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.2101 - accuracy: 0.7204 - val_loss: 14.5443 - val_accuracy: 0.0448\n",
      "Epoch 99/100\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.1921 - accuracy: 0.7287 - val_loss: 14.6709 - val_accuracy: 0.0430\n",
      "Epoch 100/100\n",
      "276/276 [==============================] - 7s 24ms/step - loss: 1.1872 - accuracy: 0.7255 - val_loss: 14.7124 - val_accuracy: 0.0426\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=100, validation_data=(x_test,y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d28f18",
   "metadata": {},
   "source": [
    "## Prediction Function\n",
    "\n",
    "This function predicts the next word given an input text using a trained LSTM model.\n",
    "\n",
    "###  How It Works:\n",
    "1. **Tokenization**: Converts the input text into a sequence of integers.\n",
    "2. **Trimming**: Ensures the sequence fits within the `max_sequence_len - 1` constraint by retaining only the most recent tokens if needed.\n",
    "3. **Padding**: Pads the sequence from the left to match the input length expected by the model.\n",
    "4. **Prediction**: Uses the model to predict the next words index.\n",
    "5. **Decoding**: Finds the corresponding word from the tokenizers word index.\n",
    "\n",
    "Returns the predicted word or `None` if not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c48c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, tokenizer, model, max_sequence_len):\n",
    "    token_list= tokenizer.texts_to_sequences([input_text])[0]\n",
    "    if len(token_list)>=max_sequence_len:\n",
    "        token_list=token_list[-(max_sequence_len-1):]\n",
    "    token_list= pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted= model.predict(token_list,verbose=0)\n",
    "    predicted_word_index= np.argmax(predicted, axis=1)  # We extract the index of the highest probability word\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index== predicted_word_index:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d93fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text  You are a\n",
      " Predicted word: catch\n"
     ]
    }
   ],
   "source": [
    "input_text= \" You are a\"\n",
    "max_sequence_len= model.input_shape[1]+1\n",
    "print(f\"Input text {input_text}\")\n",
    "next_word= predict_next_word(input_text, tokenizer, model, max_sequence_len )\n",
    "print(f\" Predicted word: {next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e076e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
