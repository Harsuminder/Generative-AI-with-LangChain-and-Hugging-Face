{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcbe523",
   "metadata": {},
   "source": [
    "## üîç Forget Gate in LSTM RNN ‚Äì Step-by-Step Explanation\n",
    "\n",
    "The **Forget Gate** in an LSTM RNN is responsible for deciding how much of the **past memory (cell state)** should be **retained or discarded** at each time step.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Step-by-Step Working of the Forget Gate\n",
    "\n",
    "#### üîπ Step 1: Inputs to the Forget Gate\n",
    "- The forget gate receives two inputs:\n",
    "  - `h‚Çú‚Çã‚ÇÅ`: Hidden state from the previous time step (short-term memory)\n",
    "  - `x‚Çú`: Current input\n",
    "\n",
    "#### üîπ Step 2: Concatenation\n",
    "- These two vectors are **concatenated**:\n",
    "  \\[\n",
    "  [h‚Çú‚Çã‚ÇÅ, x‚Çú]\n",
    "  \\]\n",
    "\n",
    "#### üîπ Step 3: Linear Transformation\n",
    "- The concatenated vector is passed through a **weight matrix (`W_f`)** and added to a **bias (`b_f`)**:\n",
    "  \\[\n",
    "  z_f = W_f \\cdot [h‚Çú‚Çã‚ÇÅ, x‚Çú] + b_f\n",
    "  \\]\n",
    "\n",
    "#### üîπ Step 4: Sigmoid Activation\n",
    "- A **sigmoid activation** is applied to the result:\n",
    "  \\[\n",
    "  f‚Çú = \\sigma(z_f)\n",
    "  \\]\n",
    "- This gives values between **0 and 1**:\n",
    "  - `0` ‚Üí Forget everything\n",
    "  - `1` ‚Üí Keep everything\n",
    "\n",
    "#### üîπ Step 5: Element-wise Multiplication with Cell State\n",
    "- The output `f‚Çú` is multiplied element-wise with the previous cell state `C‚Çú‚Çã‚ÇÅ`:\n",
    "  \\[\n",
    "  C‚Çú = f‚Çú * C‚Çú‚Çã‚ÇÅ\n",
    "  \\]\n",
    "- This controls how much of the previous memory is **carried forward**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Example\n",
    "\n",
    "Let:\n",
    "- `C‚Çú‚Çã‚ÇÅ = [10, 20, 30]`\n",
    "- `f‚Çú = [0.9, 0.5, 0.0]`\n",
    "\n",
    "Then:\n",
    "- `C‚Çú = [9.0, 10.0, 0.0]`\n",
    "\n",
    "**Interpretation:**\n",
    "- Keep 90% of the first memory value\n",
    "- Keep 50% of the second\n",
    "- Discard the third completely\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Why is the Forget Gate Important?\n",
    "\n",
    "- Helps the model **retain only relevant information** from the past.\n",
    "- Prevents **accumulation of unnecessary memory**.\n",
    "- Solves the **long-term dependency problem** found in vanilla RNNs.\n",
    "- Makes LSTM RNNs **more stable** and capable of learning across long sequences.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aff323",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
