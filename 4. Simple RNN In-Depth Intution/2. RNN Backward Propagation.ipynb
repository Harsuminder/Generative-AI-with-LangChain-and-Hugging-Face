{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c114f13f",
   "metadata": {},
   "source": [
    "# ğŸ”„ Backpropagation Through Time (BPTT) â€“ RNN Training Explained\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ What is Backpropagation Through Time?\n",
    "\n",
    "In a Recurrent Neural Network (RNN), we process input **step by step**, using hidden states to carry forward **contextual memory**.  \n",
    "After computing the final output and **loss**, the model must **update its parameters** to improve performance â€” this happens through **Backpropagation Through Time (BPTT)**.\n",
    "\n",
    "BPTT is an extension of backpropagation used for **sequential models**, where **gradients flow backward not just through layers**, but also **across time steps**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Example Recap: Sentence \"I like NLP\"\n",
    "\n",
    "Letâ€™s revisit our toy sentence and its one-hot encoded inputs:\n",
    "\n",
    "**Sentence:**  \n",
    "\"I like NLP\"\n",
    "\n",
    "**Time steps:**\n",
    "- t=1 â†’ xâ‚â‚ = \"I\"\n",
    "- t=2 â†’ xâ‚â‚‚ = \"like\"\n",
    "- t=3 â†’ xâ‚â‚ƒ = \"NLP\"\n",
    "\n",
    "---\n",
    "\n",
    "## â± Forward Pass (from before)\n",
    "\n",
    "At each time step, the RNN computes the hidden state:\n",
    "\n",
    "- hâ‚ = f(xâ‚â‚ â‹… W + b)  \n",
    "- hâ‚‚ = f(xâ‚â‚‚ â‹… W + hâ‚ â‹… WÊ° + b)  \n",
    "- hâ‚ƒ = f(xâ‚â‚ƒ â‹… W + hâ‚‚ â‹… WÊ° + b)\n",
    "\n",
    "Final output:\n",
    "- Å· = softmax(hâ‚ƒ â‹… V + b_output)\n",
    "\n",
    "Loss:\n",
    "- L = yÌ‚ - y  â† (difference between predicted and actual target)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Backpropagation Through Time Begins\n",
    "\n",
    "BPTT computes **gradients of the loss with respect to all weights**, including those used **at every time step**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Gradient Flow Overview\n",
    "\n",
    "We compute partial derivatives and update:\n",
    "\n",
    "1. **dL/dÅ·** â† gradient of loss w.r.t output  \n",
    "2. **Backprop through output layer**:  \n",
    "   - Update `V` and `b_output`  \n",
    "   - Formula:  \n",
    "     - âˆ‚L/âˆ‚V = hâ‚ƒáµ— Ã— (Å· - y)  \n",
    "     - V â† V - Î± Ã— âˆ‚L/âˆ‚V  \n",
    "\n",
    "3. **Backprop through hidden states** (from hâ‚ƒ â†’ hâ‚‚ â†’ hâ‚):\n",
    "   - Accumulate gradients due to recurrence\n",
    "   - Update `WÊ°` (shared at all time steps)\n",
    "   - Update `W` (input-to-hidden for xâ‚â‚, xâ‚â‚‚, xâ‚â‚ƒ)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Parameter Update â€“ Chain Rule and Weight Flow\n",
    "\n",
    "At each time step (starting from last):\n",
    "\n",
    "### ğŸ“Œ Update `V` (Hidden â†’ Output)\n",
    "- `Å·` depends on `oâ‚ƒ = hâ‚ƒ â‹… V`\n",
    "- Update rule:  \n",
    "V â† V - Î± Ã— âˆ‚L/âˆ‚V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0a848",
   "metadata": {},
   "source": [
    "\n",
    "Where:\n",
    "- âˆ‚Lâ‚œ/âˆ‚WÊ° = âˆ‚Lâ‚œ/âˆ‚hâ‚œ Ã— âˆ‚hâ‚œ/âˆ‚hâ‚œâ‚‹â‚ Ã— âˆ‚hâ‚œâ‚‹â‚/âˆ‚WÊ°\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ Update `W` (Input â†’ Hidden)\n",
    "\n",
    "Each input `xâ‚â‚`, `xâ‚â‚‚`, `xâ‚â‚ƒ` contributes separately:\n",
    "W â† W - Î± Ã— (âˆ‚Lâ‚/âˆ‚W + âˆ‚Lâ‚‚/âˆ‚W + âˆ‚Lâ‚ƒ/âˆ‚W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7626c",
   "metadata": {},
   "source": [
    "\n",
    "Use chain rule:\n",
    "- âˆ‚Lâ‚œ/âˆ‚W = âˆ‚Lâ‚œ/âˆ‚hâ‚œ Ã— âˆ‚hâ‚œ/âˆ‚xâ‚œ Ã— âˆ‚xâ‚œ/âˆ‚W\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”ƒ One Round of BPTT Summary\n",
    "\n",
    "For a 3-word sentence, backpropagation flows like this:\n",
    "\n",
    "- Time t = 3  \n",
    "  - Gradients flow: Å· â†’ oâ‚ƒ â†’ hâ‚ƒ â†’ hâ‚‚ â†’ hâ‚  \n",
    "- Time t = 2  \n",
    "  - hâ‚‚ influences future loss â†’ gradient flows to hâ‚‚  \n",
    "- Time t = 1  \n",
    "  - hâ‚ is updated based on indirect impact on hâ‚‚ and hâ‚ƒ\n",
    "\n",
    "All updates are **added across time** before applying gradient descent.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§¾ Final Update Formulas (Gradient Descent)\n",
    "\n",
    "- `V â† V - Î± Ã— âˆ‚L/âˆ‚V`  \n",
    "- `W â† W - Î± Ã— (âˆ‚Lâ‚/âˆ‚W + âˆ‚Lâ‚‚/âˆ‚W + âˆ‚Lâ‚ƒ/âˆ‚W)`  \n",
    "- `WÊ° â† WÊ° - Î± Ã— (âˆ‚Lâ‚/âˆ‚WÊ° + âˆ‚Lâ‚‚/âˆ‚WÊ° + âˆ‚Lâ‚ƒ/âˆ‚WÊ°)`  \n",
    "\n",
    "Where `Î±` is the learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ Example Learning Rate and Intuition\n",
    "\n",
    "- Typical value: Î± = 0.0001 or 0.001  \n",
    "- A small Î± ensures **slow but stable** learning  \n",
    "- Too high â†’ unstable gradients  \n",
    "- Too low â†’ very slow training\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š Parameters Getting Updated\n",
    "\n",
    "| Parameter         | Used At               | Updated In BPTT |\n",
    "|------------------|------------------------|------------------|\n",
    "| W (Input â†’ Hidden)   | All time steps         | âœ… Yes            |\n",
    "| WÊ° (Hidden â†’ Hidden) | All time steps         | âœ… Yes            |\n",
    "| V (Hidden â†’ Output)  | Final output layer     | âœ… Yes            |\n",
    "| b (Hidden bias)      | All time steps         | âœ… Yes            |\n",
    "| b_output             | Output layer           | âœ… Yes            |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc3192",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## âœ… Recap\n",
    "\n",
    "- Forward pass: one word at a time â†’ hidden states â†’ final prediction\n",
    "- Backpropagation through time flows **backward across time**\n",
    "- Uses **chain rule** to update shared weights\n",
    "- Loss reduction occurs via repeated forward + backward passes until convergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db002c5f",
   "metadata": {},
   "source": [
    "## ğŸ” What Gets Updated in Backpropagation Through Time (BPTT)?\n",
    "\n",
    "During training an RNN, after performing the forward pass and calculating the loss, the model learns by **updating weights using gradients** computed through **Backpropagation Through Time (BPTT)**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ The Weights Updated in BPTT\n",
    "\n",
    "| Parameter           | Description                                   | Symbol      | Used At              |\n",
    "|---------------------|-----------------------------------------------|-------------|-----------------------|\n",
    "| Input â†’ Hidden      | Connects input word vector to hidden state     | `W`         | Every time step       |\n",
    "| Hidden â†’ Hidden     | Transfers hidden state from tâˆ’1 to t           | `WÊ°` or `U` | Every time step       |\n",
    "| Hidden â†’ Output     | Maps hidden state to prediction                | `V`         | Final step only       |\n",
    "| Hidden Bias         | Bias added before hidden layer activation      | `b`         | Every time step       |\n",
    "| Output Bias         | Bias added before softmax output               | `b_output`  | Output layer          |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§® Loss Function\n",
    "\n",
    "Let:\n",
    "- `y` be the true label\n",
    "- `Å·` be the predicted probability (output of softmax)\n",
    "\n",
    "Then the loss:  \n",
    "\\[\n",
    "\\mathcal{L} = \\text{Loss}(y, \\hat{y}) = \\hat{y} - y\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Gradient Flow: Chain Rule Applied\n",
    "\n",
    "BPTT applies the **chain rule** to compute gradients of the loss with respect to each weight matrix.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Update Formula for Output Weights `V`\n",
    "\n",
    "\\[\n",
    "V_{\\text{new}} = V_{\\text{old}} - \\alpha \\cdot \\frac{\\partial \\mathcal{L}}{\\partial V}\n",
    "\\]\n",
    "\n",
    "Using chain rule:  \n",
    "\\[\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial V} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial o} \\cdot \\frac{\\partial o}{\\partial V}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- `o = h_t â‹… V + b_output`\n",
    "- `Î±` is the learning rate\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” Update Formula for Hidden-to-Hidden Weights `WÊ°`\n",
    "\n",
    "\\[\n",
    "WÊ°_{\\text{new}} = WÊ°_{\\text{old}} - \\alpha \\cdot \\frac{\\partial \\mathcal{L}}{\\partial WÊ°}\n",
    "\\]\n",
    "\n",
    "Since `WÊ°` is reused across all time steps, gradients are **accumulated**:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial WÊ°} = \\sum_{t=1}^{T} \\left( \\frac{\\partial \\mathcal{L}}{\\partial h_t} \\cdot \\frac{\\partial h_t}{\\partial WÊ°} \\right)\n",
    "\\]\n",
    "\n",
    "This includes:\n",
    "- From time step T backward to 1\n",
    "- Each `h_t` depends on previous `h_{tâˆ’1}` through `WÊ°`\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Update Formula for Input-to-Hidden Weights `W`\n",
    "\n",
    "\\[\n",
    "W_{\\text{new}} = W_{\\text{old}} - \\alpha \\cdot \\frac{\\partial \\mathcal{L}}{\\partial W}\n",
    "\\]\n",
    "\n",
    "Using chain rule at each time step `t`:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W} = \\sum_{t=1}^{T} \\left( \\frac{\\partial \\mathcal{L}}{\\partial h_t} \\cdot \\frac{\\partial h_t}{\\partial W} \\right)\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Quick Summary of Gradient Dependencies\n",
    "\n",
    "| Weight    | Depends On                                                |\n",
    "|-----------|------------------------------------------------------------|\n",
    "| `V`       | Final hidden state `h_t`                                  |\n",
    "| `WÊ°`      | All hidden states `h_t`, `h_{t-1}`, `h_{t-2}`...           |\n",
    "| `W`       | Inputs `x_t` and their contribution to `h_t`              |\n",
    "| `b`       | Activation function input at each hidden layer            |\n",
    "| `b_output`| Output layer before softmax                               |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Intuition\n",
    "\n",
    "- The same `WÊ°` is **shared across time**, so it gets gradients from **all steps**  \n",
    "- Chain rule enables loss at the end of the sequence to influence early hidden states  \n",
    "- BPTT enables RNNs to **\"blame\" earlier time steps** and improve learning across sequences\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Final Takeaway\n",
    "\n",
    "During BPTT, we compute gradients of the loss with respect to:\n",
    "- `W`, `WÊ°`, `V` (all weights)\n",
    "- `b`, `b_output` (biases)\n",
    "\n",
    "These are updated using **gradient descent** by applying **chain rule** across time steps.  \n",
    "This is how RNNs learn temporal dependencies across a sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497be10",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
