{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c114f13f",
   "metadata": {},
   "source": [
    "# 🔄 Backpropagation Through Time (BPTT) – RNN Training Explained\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 What is Backpropagation Through Time?\n",
    "\n",
    "In a Recurrent Neural Network (RNN), we process input **step by step**, using hidden states to carry forward **contextual memory**.  \n",
    "After computing the final output and **loss**, the model must **update its parameters** to improve performance — this happens through **Backpropagation Through Time (BPTT)**.\n",
    "\n",
    "BPTT is an extension of backpropagation used for **sequential models**, where **gradients flow backward not just through layers**, but also **across time steps**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Example Recap: Sentence \"I like NLP\"\n",
    "\n",
    "Let’s revisit our toy sentence and its one-hot encoded inputs:\n",
    "\n",
    "**Sentence:**  \n",
    "\"I like NLP\"\n",
    "\n",
    "**Time steps:**\n",
    "- t=1 → x₁₁ = \"I\"\n",
    "- t=2 → x₁₂ = \"like\"\n",
    "- t=3 → x₁₃ = \"NLP\"\n",
    "\n",
    "---\n",
    "\n",
    "## ⏱ Forward Pass (from before)\n",
    "\n",
    "At each time step, the RNN computes the hidden state:\n",
    "\n",
    "- h₁ = f(x₁₁ ⋅ W + b)  \n",
    "- h₂ = f(x₁₂ ⋅ W + h₁ ⋅ Wʰ + b)  \n",
    "- h₃ = f(x₁₃ ⋅ W + h₂ ⋅ Wʰ + b)\n",
    "\n",
    "Final output:\n",
    "- ŷ = softmax(h₃ ⋅ V + b_output)\n",
    "\n",
    "Loss:\n",
    "- L = ŷ - y  ← (difference between predicted and actual target)\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Backpropagation Through Time Begins\n",
    "\n",
    "BPTT computes **gradients of the loss with respect to all weights**, including those used **at every time step**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Gradient Flow Overview\n",
    "\n",
    "We compute partial derivatives and update:\n",
    "\n",
    "1. **dL/dŷ** ← gradient of loss w.r.t output  \n",
    "2. **Backprop through output layer**:  \n",
    "   - Update `V` and `b_output`  \n",
    "   - Formula:  \n",
    "     - ∂L/∂V = h₃ᵗ × (ŷ - y)  \n",
    "     - V ← V - α × ∂L/∂V  \n",
    "\n",
    "3. **Backprop through hidden states** (from h₃ → h₂ → h₁):\n",
    "   - Accumulate gradients due to recurrence\n",
    "   - Update `Wʰ` (shared at all time steps)\n",
    "   - Update `W` (input-to-hidden for x₁₁, x₁₂, x₁₃)\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Parameter Update – Chain Rule and Weight Flow\n",
    "\n",
    "At each time step (starting from last):\n",
    "\n",
    "### 📌 Update `V` (Hidden → Output)\n",
    "- `ŷ` depends on `o₃ = h₃ ⋅ V`\n",
    "- Update rule:  \n",
    "V ← V - α × ∂L/∂V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0a848",
   "metadata": {},
   "source": [
    "\n",
    "Where:\n",
    "- ∂Lₜ/∂Wʰ = ∂Lₜ/∂hₜ × ∂hₜ/∂hₜ₋₁ × ∂hₜ₋₁/∂Wʰ\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Update `W` (Input → Hidden)\n",
    "\n",
    "Each input `x₁₁`, `x₁₂`, `x₁₃` contributes separately:\n",
    "W ← W - α × (∂L₁/∂W + ∂L₂/∂W + ∂L₃/∂W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7626c",
   "metadata": {},
   "source": [
    "\n",
    "Use chain rule:\n",
    "- ∂Lₜ/∂W = ∂Lₜ/∂hₜ × ∂hₜ/∂xₜ × ∂xₜ/∂W\n",
    "\n",
    "---\n",
    "\n",
    "## 🔃 One Round of BPTT Summary\n",
    "\n",
    "For a 3-word sentence, backpropagation flows like this:\n",
    "\n",
    "- Time t = 3  \n",
    "  - Gradients flow: ŷ → o₃ → h₃ → h₂ → h₁  \n",
    "- Time t = 2  \n",
    "  - h₂ influences future loss → gradient flows to h₂  \n",
    "- Time t = 1  \n",
    "  - h₁ is updated based on indirect impact on h₂ and h₃\n",
    "\n",
    "All updates are **added across time** before applying gradient descent.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧾 Final Update Formulas (Gradient Descent)\n",
    "\n",
    "- `V ← V - α × ∂L/∂V`  \n",
    "- `W ← W - α × (∂L₁/∂W + ∂L₂/∂W + ∂L₃/∂W)`  \n",
    "- `Wʰ ← Wʰ - α × (∂L₁/∂Wʰ + ∂L₂/∂Wʰ + ∂L₃/∂Wʰ)`  \n",
    "\n",
    "Where `α` is the learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 Example Learning Rate and Intuition\n",
    "\n",
    "- Typical value: α = 0.0001 or 0.001  \n",
    "- A small α ensures **slow but stable** learning  \n",
    "- Too high → unstable gradients  \n",
    "- Too low → very slow training\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Parameters Getting Updated\n",
    "\n",
    "| Parameter         | Used At               | Updated In BPTT |\n",
    "|------------------|------------------------|------------------|\n",
    "| W (Input → Hidden)   | All time steps         | ✅ Yes            |\n",
    "| Wʰ (Hidden → Hidden) | All time steps         | ✅ Yes            |\n",
    "| V (Hidden → Output)  | Final output layer     | ✅ Yes            |\n",
    "| b (Hidden bias)      | All time steps         | ✅ Yes            |\n",
    "| b_output             | Output layer           | ✅ Yes            |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc3192",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ✅ Recap\n",
    "\n",
    "- Forward pass: one word at a time → hidden states → final prediction\n",
    "- Backpropagation through time flows **backward across time**\n",
    "- Uses **chain rule** to update shared weights\n",
    "- Loss reduction occurs via repeated forward + backward passes until convergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db002c5f",
   "metadata": {},
   "source": [
    "## 🔁 What Gets Updated in Backpropagation Through Time (BPTT)?\n",
    "\n",
    "During training an RNN, after performing the forward pass and calculating the loss, the model learns by **updating weights using gradients** computed through **Backpropagation Through Time (BPTT)**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 The Weights Updated in BPTT\n",
    "\n",
    "| Parameter           | Description                                   | Symbol      | Used At              |\n",
    "|---------------------|-----------------------------------------------|-------------|-----------------------|\n",
    "| Input → Hidden      | Connects input word vector to hidden state     | `W`         | Every time step       |\n",
    "| Hidden → Hidden     | Transfers hidden state from t−1 to t           | `Wʰ` or `U` | Every time step       |\n",
    "| Hidden → Output     | Maps hidden state to prediction                | `V`         | Final step only       |\n",
    "| Hidden Bias         | Bias added before hidden layer activation      | `b`         | Every time step       |\n",
    "| Output Bias         | Bias added before softmax output               | `b_output`  | Output layer          |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 Loss Function\n",
    "\n",
    "Let:\n",
    "- `y` be the true label\n",
    "- `ŷ` be the predicted probability (output of softmax)\n",
    "\n",
    "Then the loss:  \n",
    "\\[\n",
    "\\mathcal{L} = \\text{Loss}(y, \\hat{y}) = \\hat{y} - y\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 Gradient Flow: Chain Rule Applied\n",
    "\n",
    "BPTT applies the **chain rule** to compute gradients of the loss with respect to each weight matrix.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Update Formula for Output Weights `V`\n",
    "\n",
    "\\[\n",
    "V_{\\text{new}} = V_{\\text{old}} - \\alpha \\cdot \\frac{\\partial \\mathcal{L}}{\\partial V}\n",
    "\\]\n",
    "\n",
    "Using chain rule:  \n",
    "\\[\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial V} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial o} \\cdot \\frac{\\partial o}{\\partial V}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- `o = h_t ⋅ V + b_output`\n",
    "- `α` is the learning rate\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Update Formula for Hidden-to-Hidden Weights `Wʰ`\n",
    "\n",
    "\\[\n",
    "Wʰ_{\\text{new}} = Wʰ_{\\text{old}} - \\alpha \\cdot \\frac{\\partial \\mathcal{L}}{\\partial Wʰ}\n",
    "\\]\n",
    "\n",
    "Since `Wʰ` is reused across all time steps, gradients are **accumulated**:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial Wʰ} = \\sum_{t=1}^{T} \\left( \\frac{\\partial \\mathcal{L}}{\\partial h_t} \\cdot \\frac{\\partial h_t}{\\partial Wʰ} \\right)\n",
    "\\]\n",
    "\n",
    "This includes:\n",
    "- From time step T backward to 1\n",
    "- Each `h_t` depends on previous `h_{t−1}` through `Wʰ`\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Update Formula for Input-to-Hidden Weights `W`\n",
    "\n",
    "\\[\n",
    "W_{\\text{new}} = W_{\\text{old}} - \\alpha \\cdot \\frac{\\partial \\mathcal{L}}{\\partial W}\n",
    "\\]\n",
    "\n",
    "Using chain rule at each time step `t`:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W} = \\sum_{t=1}^{T} \\left( \\frac{\\partial \\mathcal{L}}{\\partial h_t} \\cdot \\frac{\\partial h_t}{\\partial W} \\right)\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Quick Summary of Gradient Dependencies\n",
    "\n",
    "| Weight    | Depends On                                                |\n",
    "|-----------|------------------------------------------------------------|\n",
    "| `V`       | Final hidden state `h_t`                                  |\n",
    "| `Wʰ`      | All hidden states `h_t`, `h_{t-1}`, `h_{t-2}`...           |\n",
    "| `W`       | Inputs `x_t` and their contribution to `h_t`              |\n",
    "| `b`       | Activation function input at each hidden layer            |\n",
    "| `b_output`| Output layer before softmax                               |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Intuition\n",
    "\n",
    "- The same `Wʰ` is **shared across time**, so it gets gradients from **all steps**  \n",
    "- Chain rule enables loss at the end of the sequence to influence early hidden states  \n",
    "- BPTT enables RNNs to **\"blame\" earlier time steps** and improve learning across sequences\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Final Takeaway\n",
    "\n",
    "During BPTT, we compute gradients of the loss with respect to:\n",
    "- `W`, `Wʰ`, `V` (all weights)\n",
    "- `b`, `b_output` (biases)\n",
    "\n",
    "These are updated using **gradient descent** by applying **chain rule** across time steps.  \n",
    "This is how RNNs learn temporal dependencies across a sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497be10",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
