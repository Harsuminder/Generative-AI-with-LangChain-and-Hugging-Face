{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d8540f",
   "metadata": {},
   "source": [
    "## ğŸ” RNN Forward Propagation Through Time â€“ Conceptual Walkthrough\n",
    "\n",
    "A **Recurrent Neural Network (RNN)** processes sequential data one step at a time, maintaining memory of previous inputs using a hidden state. This is ideal for NLP tasks where **word order and context matter**, such as text generation, translation, and classification.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Example: Three Simple Sentences\n",
    "\n",
    "Weâ€™ll build a vocabulary and simulate RNN forward propagation using the following toy dataset:\n",
    "\n",
    "Sentence 1: I like NLP  \n",
    "Sentence 2: You study hard  \n",
    "Sentence 3: We write code\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š Vocabulary\n",
    "\n",
    "[\"I\", \"like\", \"NLP\", \"You\", \"study\", \"hard\", \"We\", \"write\", \"code\"]\n",
    "\n",
    "Vocabulary size = **9** (Each word is unique)  \n",
    "Weâ€™ll represent each word using **One-Hot Encoding**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¤ One-Hot Encoded Vectors for Sentence 1: \"I like NLP\"\n",
    "\n",
    "| Word   | One-Hot Vector             |\n",
    "|--------|-----------------------------|\n",
    "| I      | [1 0 0 0 0 0 0 0 0]         |\n",
    "| like   | [0 1 0 0 0 0 0 0 0]         |\n",
    "| NLP    | [0 0 1 0 0 0 0 0 0]         |\n",
    "\n",
    "---\n",
    "\n",
    "## â± Forward Propagation Through Time (Step-by-Step)\n",
    "\n",
    "We feed **one word at a time** into the RNN.\n",
    "\n",
    "Letâ€™s denote:  \n",
    "- `x11`, `x12`, `x13` as the word vectors at time steps t = 1, 2, 3  \n",
    "- `w` as the **input-to-hidden** weights  \n",
    "- `w'` as the **hidden-to-hidden** weights  \n",
    "- `b` as the bias for hidden state  \n",
    "- `f()` as an activation function (like tanh or ReLU)  \n",
    "- `h1`, `h2`, `h3` as the hidden states  \n",
    "- `Å·` as the final prediction  \n",
    "- `L` as the loss function\n",
    "\n",
    "---\n",
    "\n",
    "           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  \n",
    "x11 â”€â”€â”€â”€â”€> â”‚   RNN Cell    â”‚  \n",
    "           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  \n",
    "                  â†“  \n",
    "                h1  \n",
    "                  â†“  \n",
    "x12 â”€â”€â”€â”€â”€> â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  \n",
    "           â”‚   RNN Cell  â”‚  \n",
    "           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  \n",
    "                  â†“  \n",
    "                h2  \n",
    "                  â†“  \n",
    "x13 â”€â”€â”€â”€â”€> â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  \n",
    "           â”‚   RNN Cell  â”‚  \n",
    "           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  \n",
    "                  â†“  \n",
    "                h3 â”€â”€â”€â”€â”€> Å· (Prediction)\n",
    "---\n",
    "\n",
    "### ğŸ§® Forward Pass Equations\n",
    "\n",
    "**Time Step 1 (t = 1)**  \n",
    "Input: x11 (word \"I\")\n",
    "\n",
    "h1 = f(x11 â‹… w + b)\n",
    "\n",
    "---\n",
    "\n",
    "**Time Step 2 (t = 2)**  \n",
    "Input: x12 (word \"like\")\n",
    "\n",
    "h2 = f(x12 â‹… w + h1 â‹… w' + b)\n",
    "\n",
    "---\n",
    "\n",
    "**Time Step 3 (t = 3)**  \n",
    "Input: x13 (word \"NLP\")\n",
    "\n",
    "h3 = f(x13 â‹… w + h2 â‹… w' + b)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¤ Output and Loss Computation\n",
    "\n",
    "Å· = softmax(h3 â‹… v + b_output)\n",
    "\n",
    "Loss = y- Å·\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” Backpropagation Through Time (BPTT)\n",
    "\n",
    "- Loss is propagated backward through all time steps  \n",
    "- Gradients are calculated for all trainable parameters (`w`, `w'`, `v`, `b`, `b_output`)  \n",
    "- Parameters are updated using gradient descent\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e971b9f",
   "metadata": {},
   "source": [
    "### ğŸ”¢ Parameter Summary Example\n",
    "\n",
    "Assume:  \n",
    "- Input size (vocabulary size) = 9  \n",
    "- Hidden size = 5  \n",
    "- Output size = 3  \n",
    "\n",
    "| Component           | Shape         | Parameters |\n",
    "|---------------------|---------------|------------|\n",
    "| Input â†’ Hidden      | 9 Ã— 5         | 45         |\n",
    "| Hidden â†’ Hidden     | 5 Ã— 5         | 25         |\n",
    "| Hidden â†’ Output     | 5 Ã— 3         | 15         |\n",
    "| Biases              | 5 (hidden) + 3 (output) | 8 |\n",
    "\n",
    "*Total Trainable Parameters = 45 + 25 + 15 + 8 = 93*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df084e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
