{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¢ One-Hot Encoding\n",
    "\n",
    "After applying text preprocessing techniques like **tokenization**, **stop word removal**, **stemming**, and **lemmatization**, the next step is to **convert text into numerical format** â€” because machine learning models can't work with raw text directly.\n",
    "\n",
    "One of the simplest ways to do this is through **One-Hot Encoding**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¢ What is One-Hot Encoding?\n",
    "\n",
    "One-hot encoding is a technique to represent **categorical data** â€” such as words â€” as **binary vectors**. Itâ€™s often the first step in transforming text into a machine-readable format.\n",
    "\n",
    "Hereâ€™s how it works:\n",
    "- Each unique word in your vocabulary is assigned a distinct index.\n",
    "- A word is represented as a vector of all 0s, **except** for a 1 at the index of that word.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¢ One-Hot Encoding Example \n",
    "\n",
    "### ðŸ“˜ Sentences:\n",
    "1. `\"I love NLP\"`\n",
    "2. `\"NLP is fun\"`\n",
    "3. `\"I love fun\"`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§¾ Step 1: Build Vocabulary\n",
    "\n",
    "First, we tokenize all the sentences and extract the unique words (ignoring case):\n",
    "\n",
    "**Vocabulary:**\n",
    "[\"I\", \"love\", \"NLP\", \"is\", \"fun\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Each word is now represented as a 5-dimensional binary vector:\n",
    "\n",
    "| Word   | One-Hot Vector     |\n",
    "|--------|---------------------|\n",
    "| I      | `[1, 0, 0, 0, 0]`   |\n",
    "| love   | `[0, 1, 0, 0, 0]`   |\n",
    "| NLP    | `[0, 0, 1, 0, 0]`   |\n",
    "| is     | `[0, 0, 0, 1, 0]`   |\n",
    "| fun    | `[0, 0, 0, 0, 1]`   |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§© Step 3: Represent Each Sentence as a Sequence of Vectors\n",
    "\n",
    "Now we represent each sentence as a **sequence of one-hot vectors**, preserving both the words and their order:\n",
    "\n",
    "#### ðŸ”¹ \"I love NLP\":\n",
    "[ [1, 0, 0, 0, 0], # I [0, 1, 0, 0, 0], # love [0, 0, 1, 0, 0] # NLP ]\n",
    "\n",
    "\n",
    "#### ðŸ”¹ \"NLP is fun\":\n",
    "[ [0, 0, 1, 0, 0], # NLP [0, 0, 0, 1, 0], # is [0, 0, 0, 0, 1] # fun ]\n",
    "\n",
    "\n",
    "#### ðŸ”¹ \"I love fun\":\n",
    "[ [1, 0, 0, 0, 0], # I [0, 1, 0, 0, 0], # love [0, 0, 0, 0, 1] # fun ]\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Each word is now machine-readable, and this representation can be used as input to basic models or as a stepping stone toward more advanced embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
