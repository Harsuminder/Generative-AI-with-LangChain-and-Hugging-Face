{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ›‘ Stop Words in NLP\n",
    "\n",
    "### What are Stop Words?\n",
    "Stop words are commonly used words in a language (such as *the, is, in, and, to, for*) that **do not add much meaning** to a sentence. These words are often **filtered out** in NLP tasks to improve efficiency and focus on meaningful words.\n",
    "\n",
    "### Why Remove Stop Words?\n",
    "- Stop words appear **frequently** in text but carry **little to no contextual meaning**.\n",
    "- Removing them **reduces computational complexity** and improves **text processing efficiency**.\n",
    "- Some NLP models and applications **retain stop words** if context matters (e.g., chatbots, language models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'after', 'again']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop words in english\n",
    "stopwords.words('english')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'la', 'que', 'el', 'en']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop words in Spanish\n",
    "stopwords.words('spanish')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ›‘ Example of Stop Words Removal & Stemming using Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph= \"\"\"The quick brown fox jumps over the lazy dog. It was a bright and sunny day, but she didn't feel like going outside. He couldn't understand why the weather affected his mood so much. However, he decided not to let it bother him and continued reading his favorite book.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumps over the lazy dog.',\n",
       " \"It was a bright and sunny day, but she didn't feel like going outside.\",\n",
       " \"He couldn't understand why the weather affected his mood so much.\",\n",
       " 'However, he decided not to let it bother him and continued reading his favorite book.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=nltk.sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quick brown fox jump lazi dog .',\n",
       " \"bright sunni day , n't feel like go outsid .\",\n",
       " \"could n't understand weather affect mood much .\",\n",
       " 'howev , decid let bother continu read favorit book .']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer= PorterStemmer()\n",
    "\n",
    "# Iterate over each sentence in the list\n",
    "for i in range(len(sentences)):\n",
    "\n",
    "    # Tokenize the sentence into words\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "\n",
    "    # Apply stemming while removing stop words\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    # Join the processed words back into a sentence\n",
    "    sentences[i]= ' '.join(words)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ›‘ Example of Stop Words Removal & Stemming using Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the quick brown fox jump lazi dog .',\n",
       " \"it bright sunni day , n't feel like go outsid .\",\n",
       " \"he could n't understand weather affect mood much .\",\n",
       " 'howev , decid let bother continu read favorit book .']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer=SnowballStemmer('english')\n",
    "\n",
    "sentences=nltk.sent_tokenize(corpus)\n",
    "\n",
    "# Iterate over each sentence in the list\n",
    "for i in range(len(sentences)):\n",
    "\n",
    "    # Tokenize the sentence into words\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "\n",
    "    # Apply stemming while removing stop words\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    # Join the processed words back into a sentence\n",
    "    sentences[i]= ' '.join(words)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ›‘ Example of Stop Words Removal & Lemmatization using WordNet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the quick brown fox jump lazy dog .',\n",
       " \"it bright sunny day , n't feel like go outside .\",\n",
       " \"he could n't understand weather affect mood much .\",\n",
       " 'however , decide let bother continue read favorite book .']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "sentences=nltk.sent_tokenize(corpus)\n",
    "\n",
    "# Iterate over each sentence in the list\n",
    "for i in range(len(sentences)):\n",
    "\n",
    "    # Tokenize the sentence into words\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "\n",
    "    # Apply stemming while removing stop words\n",
    "    words=[lemmatizer.lemmatize(word.lower(), pos='v') for word in words if word not in set(stopwords.words('english'))]\n",
    "\n",
    "    # Join the processed words back into a sentence\n",
    "    sentences[i]= ' '.join(words)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ›‘ Custom Stop Words List\n",
    "\n",
    "### Why Customize Stop Words?\n",
    "While standard stop word lists are useful, they might **remove important words** that impact meaning. For example, words like **\"not\"**, **\"couldn't\"**, and **\"isn't\"** are crucial for **sentiment analysis**, and removing them might change the meaning of a sentence.\n",
    "\n",
    "### Creating a Custom Stop Words List\n",
    "Instead of using the default **NLTK stop words**, you can **modify** the list by:\n",
    "1. **Adding words that are not relevant** to your task.\n",
    "2. **Removing words that are important** (e.g., *not, never, can't*).\n",
    "\n",
    "### Example: Custom Stop Words List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence: couldn't believe not working.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load default stop words\n",
    "default_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Define important words to **keep**\n",
    "important_words = {\"not\", \"couldn't\", \"isn't\", \"never\", \"can't\", \"won't\"}\n",
    "\n",
    "# Remove important words from stop words list\n",
    "custom_stopwords = default_stopwords - important_words\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"I couldn't believe it was not working.\"\n",
    "\n",
    "# Removing stop words using the custom list\n",
    "filtered_words = [word for word in sentence.split() if word.lower() not in custom_stopwords]\n",
    "\n",
    "print(\"Filtered Sentence:\", \" \".join(filtered_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
